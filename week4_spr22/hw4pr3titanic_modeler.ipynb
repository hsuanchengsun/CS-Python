{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw4pr3titanic:  titanic-passenger clasification via nearest neighbors\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SUGGESTION:  \n",
    "# \n",
    "# +++ copy-paste-and-alter from the iris- + births + digits-cleaning notebooks into here +++\n",
    "#\n",
    "# Here, there can be value in weighting columns with different coefficients... explore!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>sexnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived     sex      age  sibsp  parch  sexnum\n",
       "0          1         1  female  29.0000      0      0       0\n",
       "1          1         1    male   0.9167      1      2       1\n",
       "2          1         0  female   2.0000      1      2       0\n",
       "3          1         0    male  30.0000      1      2       1\n",
       "4          1         0  female  25.0000      1      2       0\n",
       "...      ...       ...     ...      ...    ...    ...     ...\n",
       "1259       3         0    male  45.5000      0      0       1\n",
       "1262       3         0  female  14.5000      1      0       0\n",
       "1264       3         0    male  26.5000      0      0       1\n",
       "1265       3         0    male  27.0000      0      0       1\n",
       "1266       3         0    male  29.0000      0      0       1\n",
       "\n",
       "[1004 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy = pd.read_csv('titanic_cleaned.csv')\n",
    "df_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>sexnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived      age  sibsp  parch  sexnum\n",
       "0          1         1  29.0000      0      0       0\n",
       "1          1         1   0.9167      1      2       1\n",
       "2          1         0   2.0000      1      2       0\n",
       "3          1         0  30.0000      1      2       1\n",
       "4          1         0  25.0000      1      2       0\n",
       "...      ...       ...      ...    ...    ...     ...\n",
       "1259       3         0  45.5000      0      0       1\n",
       "1262       3         0  14.5000      1      0       0\n",
       "1264       3         0  26.5000      0      0       1\n",
       "1265       3         0  27.0000      0      0       1\n",
       "1266       3         0  29.0000      0      0       1\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1 = df_tidy.drop('sex', axis=COLUMN )\n",
    "df_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      1.     29.      0.      0.      0.    ]\n",
      " [ 1.      1.      0.9167  1.      2.      1.    ]\n",
      " [ 1.      0.      2.      1.      2.      0.    ]\n",
      " ...\n",
      " [ 3.      0.     26.5     0.      0.      1.    ]\n",
      " [ 3.      0.     27.      0.      0.      1.    ]\n",
      " [ 3.      0.     29.      0.      0.      1.    ]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "A = df_model1.to_numpy().astype('float64')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate((A[:, 0].reshape(len(A), 1), A[:, 2:]), axis = 1)\n",
    "y_all = A[:,1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_all (just the labels/species)   are \n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      "X_all (just the features) are \n",
      " [[ 1.     29.      0.      0.      0.    ]\n",
      " [ 1.      0.9167  1.      2.      1.    ]\n",
      " [ 1.      2.      1.      2.      0.    ]\n",
      " ...\n",
      " [ 3.     26.5     0.      0.      1.    ]\n",
      " [ 3.     27.      0.      0.      1.    ]\n",
      " [ 3.     29.      0.      0.      1.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_all (just the labels/species)   are \\n {y_all}\")\n",
    "print(f\"X_all (just the features) are \\n {X_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 803 rows;  testing with 201 rows\n",
      "\n",
      "Held-out data... (testing data: 201)\n",
      "y_test: [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "X_test (a few rows): [[ 3. 22.  0.  0.  1.]\n",
      " [ 3. 19.  0.  0.  1.]\n",
      " [ 3. 39.  0.  2.  1.]\n",
      " [ 3. 35.  1.  1.  0.]\n",
      " [ 2. 28.  0.  1.  1.]]\n",
      "\n",
      "Data used for modeling... (training data: 803)\n",
      "y_train: [0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "X_train (a few rows): [[ 1. 31.  1.  0.  1.]\n",
      " [ 1. 30.  0.  0.  0.]\n",
      " [ 2. 23.  0.  0.  1.]\n",
      " [ 2. 66.  0.  0.  1.]\n",
      " [ 3. 22.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\")\n",
    "print(f\"X_test (a few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\")\n",
    "print(f\"X_train (a few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a knn classifier with k = 84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 84   # we don't know what k to use, so we guess!  (this will _not_ be a good value)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)       # here, k is the \"k\" in kNN\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a knn classifier with k =\", k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Actual  labels  : [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Results on test set:  116 correct out of 201 total.\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = knn_model.predict(X_test)   \n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row   0 : 0  0   \n",
      "row   1 : 0  0   \n",
      "row   2 : 0  0   \n",
      "row   3 : 0  1   incorrect\n",
      "row   4 : 0  0   \n",
      "row   5 : 0  1   incorrect\n",
      "row   6 : 0  1   incorrect\n",
      "row   7 : 1  0   incorrect\n",
      "row   8 : 0  0   \n",
      "row   9 : 0  0   \n",
      "row  10 : 0  0   \n",
      "row  11 : 0  1   incorrect\n",
      "row  12 : 0  1   incorrect\n",
      "row  13 : 0  1   incorrect\n",
      "row  14 : 0  0   \n",
      "row  15 : 0  0   \n",
      "row  16 : 0  0   \n",
      "row  17 : 0  0   \n",
      "row  18 : 0  1   incorrect\n",
      "row  19 : 0  1   incorrect\n",
      "row  20 : 0  0   \n",
      "row  21 : 0  0   \n",
      "row  22 : 0  1   incorrect\n",
      "row  23 : 0  1   incorrect\n",
      "row  24 : 0  0   \n",
      "row  25 : 0  1   incorrect\n",
      "row  26 : 0  0   \n",
      "row  27 : 0  0   \n",
      "row  28 : 0  0   \n",
      "row  29 : 0  0   \n",
      "row  30 : 0  0   \n",
      "row  31 : 0  0   \n",
      "row  32 : 0  1   incorrect\n",
      "row  33 : 0  0   \n",
      "row  34 : 0  1   incorrect\n",
      "row  35 : 0  1   incorrect\n",
      "row  36 : 1  0   incorrect\n",
      "row  37 : 0  1   incorrect\n",
      "row  38 : 0  0   \n",
      "row  39 : 0  1   incorrect\n",
      "row  40 : 0  1   incorrect\n",
      "row  41 : 0  0   \n",
      "row  42 : 0  1   incorrect\n",
      "row  43 : 0  0   \n",
      "row  44 : 1  1   \n",
      "row  45 : 0  0   \n",
      "row  46 : 0  0   \n",
      "row  47 : 0  1   incorrect\n",
      "row  48 : 0  0   \n",
      "row  49 : 0  0   \n",
      "row  50 : 0  0   \n",
      "row  51 : 0  0   \n",
      "row  52 : 0  1   incorrect\n",
      "row  53 : 0  0   \n",
      "row  54 : 0  1   incorrect\n",
      "row  55 : 0  1   incorrect\n",
      "row  56 : 0  1   incorrect\n",
      "row  57 : 0  1   incorrect\n",
      "row  58 : 0  1   incorrect\n",
      "row  59 : 0  1   incorrect\n",
      "row  60 : 0  0   \n",
      "row  61 : 0  0   \n",
      "row  62 : 0  0   \n",
      "row  63 : 0  0   \n",
      "row  64 : 0  1   incorrect\n",
      "row  65 : 0  0   \n",
      "row  66 : 0  0   \n",
      "row  67 : 0  0   \n",
      "row  68 : 1  1   \n",
      "row  69 : 0  0   \n",
      "row  70 : 0  1   incorrect\n",
      "row  71 : 0  1   incorrect\n",
      "row  72 : 0  1   incorrect\n",
      "row  73 : 0  0   \n",
      "row  74 : 0  1   incorrect\n",
      "row  75 : 0  0   \n",
      "row  76 : 0  0   \n",
      "row  77 : 0  1   incorrect\n",
      "row  78 : 0  1   incorrect\n",
      "row  79 : 0  1   incorrect\n",
      "row  80 : 0  1   incorrect\n",
      "row  81 : 0  0   \n",
      "row  82 : 0  1   incorrect\n",
      "row  83 : 0  1   incorrect\n",
      "row  84 : 0  0   \n",
      "row  85 : 0  0   \n",
      "row  86 : 0  0   \n",
      "row  87 : 0  0   \n",
      "row  88 : 0  1   incorrect\n",
      "row  89 : 0  1   incorrect\n",
      "row  90 : 0  0   \n",
      "row  91 : 0  0   \n",
      "row  92 : 0  1   incorrect\n",
      "row  93 : 0  0   \n",
      "row  94 : 1  1   \n",
      "row  95 : 0  0   \n",
      "row  96 : 0  0   \n",
      "row  97 : 0  0   \n",
      "row  98 : 1  1   \n",
      "row  99 : 0  1   incorrect\n",
      "row 100 : 0  1   incorrect\n",
      "row 101 : 0  0   \n",
      "row 102 : 0  1   incorrect\n",
      "row 103 : 0  0   \n",
      "row 104 : 1  1   \n",
      "row 105 : 0  1   incorrect\n",
      "row 106 : 0  1   incorrect\n",
      "row 107 : 0  1   incorrect\n",
      "row 108 : 1  1   \n",
      "row 109 : 0  0   \n",
      "row 110 : 0  0   \n",
      "row 111 : 0  0   \n",
      "row 112 : 0  0   \n",
      "row 113 : 0  0   \n",
      "row 114 : 0  0   \n",
      "row 115 : 0  1   incorrect\n",
      "row 116 : 0  0   \n",
      "row 117 : 0  1   incorrect\n",
      "row 118 : 0  1   incorrect\n",
      "row 119 : 0  0   \n",
      "row 120 : 0  1   incorrect\n",
      "row 121 : 1  1   \n",
      "row 122 : 0  1   incorrect\n",
      "row 123 : 0  1   incorrect\n",
      "row 124 : 1  1   \n",
      "row 125 : 0  1   incorrect\n",
      "row 126 : 0  0   \n",
      "row 127 : 0  0   \n",
      "row 128 : 0  1   incorrect\n",
      "row 129 : 0  1   incorrect\n",
      "row 130 : 0  0   \n",
      "row 131 : 0  0   \n",
      "row 132 : 0  0   \n",
      "row 133 : 0  1   incorrect\n",
      "row 134 : 0  0   \n",
      "row 135 : 0  0   \n",
      "row 136 : 0  0   \n",
      "row 137 : 0  0   \n",
      "row 138 : 1  0   incorrect\n",
      "row 139 : 0  1   incorrect\n",
      "row 140 : 0  1   incorrect\n",
      "row 141 : 0  1   incorrect\n",
      "row 142 : 0  1   incorrect\n",
      "row 143 : 0  0   \n",
      "row 144 : 0  0   \n",
      "row 145 : 0  0   \n",
      "row 146 : 0  1   incorrect\n",
      "row 147 : 0  1   incorrect\n",
      "row 148 : 0  0   \n",
      "row 149 : 0  0   \n",
      "row 150 : 0  1   incorrect\n",
      "row 151 : 1  0   incorrect\n",
      "row 152 : 0  0   \n",
      "row 153 : 0  1   incorrect\n",
      "row 154 : 0  1   incorrect\n",
      "row 155 : 0  1   incorrect\n",
      "row 156 : 0  0   \n",
      "row 157 : 0  0   \n",
      "row 158 : 0  1   incorrect\n",
      "row 159 : 0  1   incorrect\n",
      "row 160 : 0  1   incorrect\n",
      "row 161 : 1  0   incorrect\n",
      "row 162 : 0  0   \n",
      "row 163 : 0  0   \n",
      "row 164 : 0  0   \n",
      "row 165 : 0  0   \n",
      "row 166 : 0  0   \n",
      "row 167 : 0  0   \n",
      "row 168 : 1  1   \n",
      "row 169 : 0  0   \n",
      "row 170 : 0  0   \n",
      "row 171 : 0  0   \n",
      "row 172 : 0  0   \n",
      "row 173 : 0  0   \n",
      "row 174 : 0  1   incorrect\n",
      "row 175 : 0  0   \n",
      "row 176 : 1  1   \n",
      "row 177 : 0  0   \n",
      "row 178 : 0  1   incorrect\n",
      "row 179 : 0  1   incorrect\n",
      "row 180 : 1  0   incorrect\n",
      "row 181 : 0  1   incorrect\n",
      "row 182 : 0  0   \n",
      "row 183 : 0  0   \n",
      "row 184 : 1  1   \n",
      "row 185 : 1  1   \n",
      "row 186 : 0  1   incorrect\n",
      "row 187 : 0  1   incorrect\n",
      "row 188 : 0  0   \n",
      "row 189 : 0  0   \n",
      "row 190 : 0  1   incorrect\n",
      "row 191 : 0  0   \n",
      "row 192 : 0  1   incorrect\n",
      "row 193 : 0  0   \n",
      "row 194 : 0  0   \n",
      "row 195 : 0  1   incorrect\n",
      "row 196 : 0  1   incorrect\n",
      "row 197 : 0  0   \n",
      "row 198 : 0  0   \n",
      "row 199 : 1  1   \n",
      "row 200 : 0  0   \n",
      "\n",
      "Correct: 116 out of 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    NUM_LABELS = len(predicted_labels)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            num_correct += 1  # and we count a match!\n",
    "\n",
    "        print(f\"row {i:>3d} : {p}  {a}   {result}\")   \n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "    return num_correct\n",
    "\n",
    "# let's try it out!\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict 1 from Features [2, 4.2, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def predictive_model( Features ):\n",
    "    \"\"\" input: a list of four features \n",
    "                [ sepallen, sepalwid, petallen, petalwid ]\n",
    "        output: the predicted species of iris, from\n",
    "                  setosa (0), versicolor (1), virginica (2)\n",
    "    \"\"\"\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = knn_model.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    return predicted_species\n",
    "    \n",
    "#\n",
    "Features = [2, 4.2, 0, 0, 1]  # [5.8,2.7,4.1,1.0] [4.6,3.6,3.0,2.2] [6.7,3.3,5.7,2.1]\n",
    "result = predictive_model( Features )\n",
    "print(f\"I predict {result} from Features {Features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68322981 0.70186335 0.68322981 0.70186335 0.67295597]\n",
      "k:  1  cv accuracy:  0.6886\n",
      "[0.71428571 0.69565217 0.68944099 0.72670807 0.67295597]\n",
      "k:  2  cv accuracy:  0.6998\n",
      "[0.77018634 0.72049689 0.72049689 0.75776398 0.71069182]\n",
      "k:  3  cv accuracy:  0.7359\n",
      "[0.73913043 0.70186335 0.69565217 0.72049689 0.71698113]\n",
      "k:  4  cv accuracy:  0.7148\n",
      "[0.79503106 0.74534161 0.72049689 0.74534161 0.72327044]\n",
      "k:  5  cv accuracy:  0.7459\n",
      "[0.7515528  0.71428571 0.70186335 0.73913043 0.72327044]\n",
      "k:  6  cv accuracy:  0.7260\n",
      "[0.80745342 0.74534161 0.71428571 0.73913043 0.72955975]\n",
      "k:  7  cv accuracy:  0.7472\n",
      "[0.79503106 0.72049689 0.72049689 0.72049689 0.73584906]\n",
      "k:  8  cv accuracy:  0.7385\n",
      "[0.80124224 0.7515528  0.73291925 0.72670807 0.74213836]\n",
      "k:  9  cv accuracy:  0.7509\n",
      "[0.78881988 0.72670807 0.70807453 0.70807453 0.72327044]\n",
      "k: 10  cv accuracy:  0.7310\n",
      "[0.78881988 0.74534161 0.70807453 0.73291925 0.74842767]\n",
      "k: 11  cv accuracy:  0.7447\n",
      "[0.77639752 0.72049689 0.69565217 0.73913043 0.72955975]\n",
      "k: 12  cv accuracy:  0.7322\n",
      "[0.80124224 0.73913043 0.68944099 0.75776398 0.72955975]\n",
      "k: 13  cv accuracy:  0.7434\n",
      "[0.7515528  0.73913043 0.68322981 0.74534161 0.73584906]\n",
      "k: 14  cv accuracy:  0.7310\n",
      "[0.75776398 0.76397516 0.67701863 0.72670807 0.75471698]\n",
      "k: 15  cv accuracy:  0.7360\n",
      "[0.70186335 0.75776398 0.68944099 0.71428571 0.7672956 ]\n",
      "k: 16  cv accuracy:  0.7261\n",
      "[0.73913043 0.75776398 0.68944099 0.70807453 0.75471698]\n",
      "k: 17  cv accuracy:  0.7298\n",
      "[0.71428571 0.73913043 0.66459627 0.70807453 0.76100629]\n",
      "k: 18  cv accuracy:  0.7174\n",
      "[0.73913043 0.77018634 0.67080745 0.70807453 0.74842767]\n",
      "k: 19  cv accuracy:  0.7273\n",
      "[0.72049689 0.72670807 0.65217391 0.67080745 0.72955975]\n",
      "k: 20  cv accuracy:  0.6999\n",
      "[0.72670807 0.74534161 0.67080745 0.68944099 0.74213836]\n",
      "k: 21  cv accuracy:  0.7149\n",
      "[0.70186335 0.72049689 0.65838509 0.68944099 0.74842767]\n",
      "k: 22  cv accuracy:  0.7037\n",
      "[0.73291925 0.73913043 0.66459627 0.68944099 0.74213836]\n",
      "k: 23  cv accuracy:  0.7136\n",
      "[0.72049689 0.7515528  0.65838509 0.68322981 0.76100629]\n",
      "k: 24  cv accuracy:  0.7149\n",
      "[0.72670807 0.7515528  0.63354037 0.68944099 0.77358491]\n",
      "k: 25  cv accuracy:  0.7150\n",
      "[0.72049689 0.72670807 0.63975155 0.68322981 0.75471698]\n",
      "k: 26  cv accuracy:  0.7050\n",
      "[0.73291925 0.72670807 0.62111801 0.68944099 0.76100629]\n",
      "k: 27  cv accuracy:  0.7062\n",
      "[0.72049689 0.68944099 0.64596273 0.68944099 0.73584906]\n",
      "k: 28  cv accuracy:  0.6962\n",
      "[0.71428571 0.70186335 0.62111801 0.68944099 0.74213836]\n",
      "k: 29  cv accuracy:  0.6938\n",
      "[0.68944099 0.68322981 0.63354037 0.68944099 0.71698113]\n",
      "k: 30  cv accuracy:  0.6825\n",
      "[0.69565217 0.68944099 0.63354037 0.69565217 0.74842767]\n",
      "k: 31  cv accuracy:  0.6925\n",
      "[0.67701863 0.68322981 0.62732919 0.68944099 0.70440252]\n",
      "k: 32  cv accuracy:  0.6763\n",
      "[0.68944099 0.68322981 0.61490683 0.68322981 0.72327044]\n",
      "k: 33  cv accuracy:  0.6788\n",
      "[0.67701863 0.67701863 0.59627329 0.69565217 0.71069182]\n",
      "k: 34  cv accuracy:  0.6713\n",
      "[0.68944099 0.67080745 0.58385093 0.67701863 0.71069182]\n",
      "k: 35  cv accuracy:  0.6664\n",
      "[0.66459627 0.66459627 0.58385093 0.68944099 0.70440252]\n",
      "k: 36  cv accuracy:  0.6614\n",
      "[0.68322981 0.67080745 0.59627329 0.67701863 0.72955975]\n",
      "k: 37  cv accuracy:  0.6714\n",
      "[0.63354037 0.67701863 0.60248447 0.67080745 0.67924528]\n",
      "k: 38  cv accuracy:  0.6526\n",
      "[0.63354037 0.68322981 0.59006211 0.67701863 0.69811321]\n",
      "k: 39  cv accuracy:  0.6564\n",
      "[0.62732919 0.66459627 0.60248447 0.68944099 0.68553459]\n",
      "k: 40  cv accuracy:  0.6539\n",
      "[0.61490683 0.66459627 0.59006211 0.67080745 0.69811321]\n",
      "k: 41  cv accuracy:  0.6477\n",
      "[0.60869565 0.67701863 0.60869565 0.67701863 0.67924528]\n",
      "k: 42  cv accuracy:  0.6501\n",
      "[0.62732919 0.67701863 0.59006211 0.68322981 0.67295597]\n",
      "k: 43  cv accuracy:  0.6501\n",
      "[0.63354037 0.67701863 0.59627329 0.67701863 0.67295597]\n",
      "k: 44  cv accuracy:  0.6514\n",
      "[0.62732919 0.68944099 0.59627329 0.67080745 0.67295597]\n",
      "k: 45  cv accuracy:  0.6514\n",
      "[0.63975155 0.68322981 0.59006211 0.65217391 0.66666667]\n",
      "k: 46  cv accuracy:  0.6464\n",
      "[0.63354037 0.68322981 0.59006211 0.66459627 0.67295597]\n",
      "k: 47  cv accuracy:  0.6489\n",
      "[0.62732919 0.67080745 0.60248447 0.62111801 0.67295597]\n",
      "k: 48  cv accuracy:  0.6389\n",
      "[0.62732919 0.68944099 0.59627329 0.62111801 0.67924528]\n",
      "k: 49  cv accuracy:  0.6427\n",
      "[0.62111801 0.67080745 0.60869565 0.62111801 0.67295597]\n",
      "k: 50  cv accuracy:  0.6389\n",
      "[0.62111801 0.67701863 0.59627329 0.65217391 0.66666667]\n",
      "k: 51  cv accuracy:  0.6427\n",
      "[0.62732919 0.66459627 0.61490683 0.62111801 0.66037736]\n",
      "k: 52  cv accuracy:  0.6377\n",
      "[0.63975155 0.66459627 0.61490683 0.62732919 0.66037736]\n",
      "k: 53  cv accuracy:  0.6414\n",
      "[0.63354037 0.66459627 0.60248447 0.59627329 0.63522013]\n",
      "k: 54  cv accuracy:  0.6264\n",
      "[0.62732919 0.66459627 0.62111801 0.62732919 0.65408805]\n",
      "k: 55  cv accuracy:  0.6389\n",
      "[0.61490683 0.65838509 0.60869565 0.62111801 0.62893082]\n",
      "k: 56  cv accuracy:  0.6264\n",
      "[0.61490683 0.65217391 0.60248447 0.65838509 0.62264151]\n",
      "k: 57  cv accuracy:  0.6301\n",
      "[0.61490683 0.65838509 0.60869565 0.63354037 0.62893082]\n",
      "k: 58  cv accuracy:  0.6289\n",
      "[0.61490683 0.65217391 0.60869565 0.65838509 0.63522013]\n",
      "k: 59  cv accuracy:  0.6339\n",
      "[0.61490683 0.64596273 0.61490683 0.60869565 0.63522013]\n",
      "k: 60  cv accuracy:  0.6239\n",
      "[0.62732919 0.65217391 0.60869565 0.60869565 0.62893082]\n",
      "k: 61  cv accuracy:  0.6252\n",
      "[0.62111801 0.65217391 0.60869565 0.61490683 0.62893082]\n",
      "k: 62  cv accuracy:  0.6252\n",
      "[0.63354037 0.65217391 0.61490683 0.61490683 0.63522013]\n",
      "k: 63  cv accuracy:  0.6301\n",
      "[0.60869565 0.65217391 0.60869565 0.61490683 0.62893082]\n",
      "k: 64  cv accuracy:  0.6227\n",
      "[0.60869565 0.65217391 0.60869565 0.65838509 0.64150943]\n",
      "k: 65  cv accuracy:  0.6339\n",
      "[0.60248447 0.64596273 0.60869565 0.63354037 0.63522013]\n",
      "k: 66  cv accuracy:  0.6252\n",
      "[0.61490683 0.63975155 0.59006211 0.66459627 0.62893082]\n",
      "k: 67  cv accuracy:  0.6276\n",
      "[0.59627329 0.64596273 0.60869565 0.62111801 0.62264151]\n",
      "k: 68  cv accuracy:  0.6189\n",
      "[0.60869565 0.64596273 0.60869565 0.60869565 0.66037736]\n",
      "k: 69  cv accuracy:  0.6265\n",
      "[0.58385093 0.63975155 0.60869565 0.61490683 0.65408805]\n",
      "k: 70  cv accuracy:  0.6203\n",
      "[0.58385093 0.63975155 0.61490683 0.62111801 0.66666667]\n",
      "k: 71  cv accuracy:  0.6253\n",
      "[0.58385093 0.63354037 0.60248447 0.60248447 0.65408805]\n",
      "k: 72  cv accuracy:  0.6153\n",
      "[0.58385093 0.63354037 0.60248447 0.62111801 0.66037736]\n",
      "k: 73  cv accuracy:  0.6203\n",
      "[0.58385093 0.62732919 0.60248447 0.62111801 0.65408805]\n",
      "k: 74  cv accuracy:  0.6178\n",
      "[0.58385093 0.62732919 0.60248447 0.63975155 0.65408805]\n",
      "k: 75  cv accuracy:  0.6215\n",
      "[0.58385093 0.62732919 0.60248447 0.62732919 0.65408805]\n",
      "k: 76  cv accuracy:  0.6190\n",
      "[0.58385093 0.62732919 0.60248447 0.64596273 0.66037736]\n",
      "k: 77  cv accuracy:  0.6240\n",
      "[0.58385093 0.63975155 0.60248447 0.60869565 0.64779874]\n",
      "k: 78  cv accuracy:  0.6165\n",
      "[0.58385093 0.62111801 0.60248447 0.60869565 0.65408805]\n",
      "k: 79  cv accuracy:  0.6140\n",
      "[0.58385093 0.62111801 0.60248447 0.61490683 0.63522013]\n",
      "k: 80  cv accuracy:  0.6115\n",
      "[0.58385093 0.62111801 0.60248447 0.60869565 0.65408805]\n",
      "k: 81  cv accuracy:  0.6140\n",
      "[0.58385093 0.61490683 0.60248447 0.60869565 0.64779874]\n",
      "k: 82  cv accuracy:  0.6115\n",
      "[0.58385093 0.62111801 0.60248447 0.60869565 0.65408805]\n",
      "k: 83  cv accuracy:  0.6140\n",
      "[0.58385093 0.61490683 0.60248447 0.60869565 0.62893082]\n",
      "k: 84  cv accuracy:  0.6078\n",
      "best_k = 9   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "best_k = 84  # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,85):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "# assign best value of k to best_k\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_k = k      # at the moment this is incorrect   TO DO for hw4pr1: fix this...\n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a knn classifier, now tuned with a (best) k of 9\n"
     ]
    }
   ],
   "source": [
    "best_k = 9\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_tuned = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k!\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Created + trained a knn classifier, now tuned with a (best) k of {best_k}\")  \n",
    "\n",
    "# How does it do?!  The next cell will show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Actual labels: [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Results on test set:  142 correct out of 201 total.\n",
      "\n",
      "\n",
      "row   0 : 0  0   \n",
      "row   1 : 0  0   \n",
      "row   2 : 0  0   \n",
      "row   3 : 0  1   incorrect\n",
      "row   4 : 0  0   \n",
      "row   5 : 0  1   incorrect\n",
      "row   6 : 0  1   incorrect\n",
      "row   7 : 0  0   \n",
      "row   8 : 0  0   \n",
      "row   9 : 0  0   \n",
      "row  10 : 0  0   \n",
      "row  11 : 1  1   \n",
      "row  12 : 1  1   \n",
      "row  13 : 1  1   \n",
      "row  14 : 0  0   \n",
      "row  15 : 0  0   \n",
      "row  16 : 0  0   \n",
      "row  17 : 0  0   \n",
      "row  18 : 0  1   incorrect\n",
      "row  19 : 1  1   \n",
      "row  20 : 1  0   incorrect\n",
      "row  21 : 0  0   \n",
      "row  22 : 1  1   \n",
      "row  23 : 1  1   \n",
      "row  24 : 1  0   incorrect\n",
      "row  25 : 0  1   incorrect\n",
      "row  26 : 0  0   \n",
      "row  27 : 0  0   \n",
      "row  28 : 0  0   \n",
      "row  29 : 0  0   \n",
      "row  30 : 0  0   \n",
      "row  31 : 0  0   \n",
      "row  32 : 0  1   incorrect\n",
      "row  33 : 1  0   incorrect\n",
      "row  34 : 0  1   incorrect\n",
      "row  35 : 1  1   \n",
      "row  36 : 0  0   \n",
      "row  37 : 1  1   \n",
      "row  38 : 1  0   incorrect\n",
      "row  39 : 0  1   incorrect\n",
      "row  40 : 1  1   \n",
      "row  41 : 0  0   \n",
      "row  42 : 1  1   \n",
      "row  43 : 0  0   \n",
      "row  44 : 1  1   \n",
      "row  45 : 0  0   \n",
      "row  46 : 0  0   \n",
      "row  47 : 1  1   \n",
      "row  48 : 0  0   \n",
      "row  49 : 0  0   \n",
      "row  50 : 0  0   \n",
      "row  51 : 0  0   \n",
      "row  52 : 1  1   \n",
      "row  53 : 0  0   \n",
      "row  54 : 1  1   \n",
      "row  55 : 0  1   incorrect\n",
      "row  56 : 0  1   incorrect\n",
      "row  57 : 0  1   incorrect\n",
      "row  58 : 0  1   incorrect\n",
      "row  59 : 0  1   incorrect\n",
      "row  60 : 0  0   \n",
      "row  61 : 0  0   \n",
      "row  62 : 0  0   \n",
      "row  63 : 0  0   \n",
      "row  64 : 0  1   incorrect\n",
      "row  65 : 0  0   \n",
      "row  66 : 0  0   \n",
      "row  67 : 1  0   incorrect\n",
      "row  68 : 1  1   \n",
      "row  69 : 0  0   \n",
      "row  70 : 1  1   \n",
      "row  71 : 1  1   \n",
      "row  72 : 0  1   incorrect\n",
      "row  73 : 0  0   \n",
      "row  74 : 0  1   incorrect\n",
      "row  75 : 0  0   \n",
      "row  76 : 0  0   \n",
      "row  77 : 0  1   incorrect\n",
      "row  78 : 1  1   \n",
      "row  79 : 0  1   incorrect\n",
      "row  80 : 1  1   \n",
      "row  81 : 0  0   \n",
      "row  82 : 1  1   \n",
      "row  83 : 0  1   incorrect\n",
      "row  84 : 1  0   incorrect\n",
      "row  85 : 0  0   \n",
      "row  86 : 0  0   \n",
      "row  87 : 1  0   incorrect\n",
      "row  88 : 0  1   incorrect\n",
      "row  89 : 0  1   incorrect\n",
      "row  90 : 0  0   \n",
      "row  91 : 1  0   incorrect\n",
      "row  92 : 0  1   incorrect\n",
      "row  93 : 0  0   \n",
      "row  94 : 1  1   \n",
      "row  95 : 0  0   \n",
      "row  96 : 0  0   \n",
      "row  97 : 0  0   \n",
      "row  98 : 1  1   \n",
      "row  99 : 1  1   \n",
      "row 100 : 0  1   incorrect\n",
      "row 101 : 0  0   \n",
      "row 102 : 1  1   \n",
      "row 103 : 0  0   \n",
      "row 104 : 0  1   incorrect\n",
      "row 105 : 1  1   \n",
      "row 106 : 0  1   incorrect\n",
      "row 107 : 0  1   incorrect\n",
      "row 108 : 1  1   \n",
      "row 109 : 0  0   \n",
      "row 110 : 0  0   \n",
      "row 111 : 0  0   \n",
      "row 112 : 1  0   incorrect\n",
      "row 113 : 0  0   \n",
      "row 114 : 0  0   \n",
      "row 115 : 1  1   \n",
      "row 116 : 1  0   incorrect\n",
      "row 117 : 0  1   incorrect\n",
      "row 118 : 1  1   \n",
      "row 119 : 0  0   \n",
      "row 120 : 1  1   \n",
      "row 121 : 1  1   \n",
      "row 122 : 0  1   incorrect\n",
      "row 123 : 0  1   incorrect\n",
      "row 124 : 1  1   \n",
      "row 125 : 0  1   incorrect\n",
      "row 126 : 1  0   incorrect\n",
      "row 127 : 0  0   \n",
      "row 128 : 1  1   \n",
      "row 129 : 1  1   \n",
      "row 130 : 0  0   \n",
      "row 131 : 0  0   \n",
      "row 132 : 0  0   \n",
      "row 133 : 0  1   incorrect\n",
      "row 134 : 1  0   incorrect\n",
      "row 135 : 0  0   \n",
      "row 136 : 0  0   \n",
      "row 137 : 0  0   \n",
      "row 138 : 0  0   \n",
      "row 139 : 1  1   \n",
      "row 140 : 0  1   incorrect\n",
      "row 141 : 0  1   incorrect\n",
      "row 142 : 1  1   \n",
      "row 143 : 1  0   incorrect\n",
      "row 144 : 0  0   \n",
      "row 145 : 0  0   \n",
      "row 146 : 0  1   incorrect\n",
      "row 147 : 0  1   incorrect\n",
      "row 148 : 0  0   \n",
      "row 149 : 0  0   \n",
      "row 150 : 0  1   incorrect\n",
      "row 151 : 0  0   \n",
      "row 152 : 0  0   \n",
      "row 153 : 0  1   incorrect\n",
      "row 154 : 1  1   \n",
      "row 155 : 0  1   incorrect\n",
      "row 156 : 0  0   \n",
      "row 157 : 0  0   \n",
      "row 158 : 1  1   \n",
      "row 159 : 1  1   \n",
      "row 160 : 1  1   \n",
      "row 161 : 0  0   \n",
      "row 162 : 0  0   \n",
      "row 163 : 0  0   \n",
      "row 164 : 0  0   \n",
      "row 165 : 0  0   \n",
      "row 166 : 0  0   \n",
      "row 167 : 0  0   \n",
      "row 168 : 1  1   \n",
      "row 169 : 0  0   \n",
      "row 170 : 1  0   incorrect\n",
      "row 171 : 0  0   \n",
      "row 172 : 0  0   \n",
      "row 173 : 1  0   incorrect\n",
      "row 174 : 1  1   \n",
      "row 175 : 0  0   \n",
      "row 176 : 1  1   \n",
      "row 177 : 0  0   \n",
      "row 178 : 0  1   incorrect\n",
      "row 179 : 0  1   incorrect\n",
      "row 180 : 0  0   \n",
      "row 181 : 0  1   incorrect\n",
      "row 182 : 0  0   \n",
      "row 183 : 0  0   \n",
      "row 184 : 1  1   \n",
      "row 185 : 1  1   \n",
      "row 186 : 0  1   incorrect\n",
      "row 187 : 1  1   \n",
      "row 188 : 0  0   \n",
      "row 189 : 0  0   \n",
      "row 190 : 0  1   incorrect\n",
      "row 191 : 0  0   \n",
      "row 192 : 0  1   incorrect\n",
      "row 193 : 0  0   \n",
      "row 194 : 0  0   \n",
      "row 195 : 1  1   \n",
      "row 196 : 1  1   \n",
      "row 197 : 0  0   \n",
      "row 198 : 0  0   \n",
      "row 199 : 1  1   \n",
      "row 200 : 0  0   \n",
      "\n",
      "Correct: 142 out of 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = knn_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\\n\\n\")\n",
    "\n",
    "# Plus, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
