{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw4pr1births_modeler:  birth classification by month + day    (above/below median: 190942)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SUGGESTION:  \n",
    "# \n",
    "#       +++ copy-paste-and-alter from the iris-modeling notebook to here +++\n",
    "#\n",
    "# This approach has the advantage of more deeply \"digesting\" the iris workflow...\n",
    "#      ...altering the parts that don't transfer, and taking the parts that do\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "births_cleaned.csv : file read into a pandas dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>births</th>\n",
       "      <th>above/below median</th>\n",
       "      <th>mediannum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>46420</td>\n",
       "      <td>below</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>153778</td>\n",
       "      <td>below</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160369</td>\n",
       "      <td>below</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>165050</td>\n",
       "      <td>below</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>169896</td>\n",
       "      <td>below</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>211263</td>\n",
       "      <td>above</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>211362</td>\n",
       "      <td>above</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>212673</td>\n",
       "      <td>above</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>212817</td>\n",
       "      <td>above</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>212915</td>\n",
       "      <td>above</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  births above/below median  mediannum\n",
       "6        2   29   46420              below          0\n",
       "7       12   25  153778              below          0\n",
       "8        1    1  160369              below          0\n",
       "9       12   24  165050              below          0\n",
       "10       1    2  169896              below          0\n",
       "..     ...  ...     ...                ...        ...\n",
       "367      9   17  211263              above          1\n",
       "368      9   24  211362              above          1\n",
       "369      9   22  212673              above          1\n",
       "370      9   23  212817              above          1\n",
       "371      9   16  212915              above          1\n",
       "\n",
       "[366 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_filename = \"births_cleaned.csv\"\n",
    "df_tidy = pd.read_csv(cleaned_filename)   # encoding=\"utf-8\" et al.\n",
    "print(f\"{cleaned_filename} : file read into a pandas dataframe.\")\n",
    "df_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mediannum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  mediannum\n",
       "6        2   29          0\n",
       "7       12   25          0\n",
       "8        1    1          0\n",
       "9       12   24          0\n",
       "10       1    2          0\n",
       "..     ...  ...        ...\n",
       "367      9   17          1\n",
       "368      9   24          1\n",
       "369      9   22          1\n",
       "370      9   23          1\n",
       "371      9   16          1\n",
       "\n",
       "[366 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1 = df_tidy.drop(['above/below median', 'births'], axis=1 )\n",
    "df_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df_model1.to_numpy()\n",
    "A = A.astype('float64')\n",
    "\n",
    "X_all = A[:,0:2]  \n",
    "y_all = A[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "X_labeled = X_all[indices]              # we apply the _same_ permutation to each!\n",
    "y_labeled = y_all[indices]              # again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 292 rows;  testing with 74 rows\n",
      "\n",
      "Held-out data... (testing data: 74)\n",
      "y_test: [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1.]\n",
      "X_test (a few rows): [[ 3. 11.]\n",
      " [ 4. 11.]\n",
      " [ 5.  4.]\n",
      " [ 8. 13.]\n",
      " [ 1. 24.]]\n",
      "\n",
      "Data used for modeling... (training data: 292)\n",
      "y_train: [1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0.]\n",
      "X_train (a few rows): [[ 9. 12.]\n",
      " [ 6. 22.]\n",
      " [ 1.  6.]\n",
      " [12. 13.]\n",
      " [ 9. 18.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\")\n",
    "print(f\"X_test (a few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\")\n",
    "print(f\"X_train (a few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=84, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 84   # we don't know what k to use, so we guess!  (this will _not_ be a good value)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)       # here, k is the \"k\" in kNN\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1.]\n",
      "Actual  labels  : [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1.]\n",
      "\n",
      "Results on test set:  55 correct out of 74 total.\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = knn_model.predict(X_test)   \n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1  cv accuracy:  0.8016\n",
      "k:  2  cv accuracy:  0.8051\n",
      "k:  3  cv accuracy:  0.8255\n",
      "k:  4  cv accuracy:  0.8427\n",
      "k:  5  cv accuracy:  0.8327\n",
      "k:  6  cv accuracy:  0.8190\n",
      "k:  7  cv accuracy:  0.8497\n",
      "k:  8  cv accuracy:  0.8462\n",
      "k:  9  cv accuracy:  0.8563\n",
      "k: 10  cv accuracy:  0.8564\n",
      "k: 11  cv accuracy:  0.8495\n",
      "k: 12  cv accuracy:  0.8324\n",
      "k: 13  cv accuracy:  0.8321\n",
      "k: 14  cv accuracy:  0.8391\n",
      "k: 15  cv accuracy:  0.8252\n",
      "k: 16  cv accuracy:  0.8388\n",
      "k: 17  cv accuracy:  0.8354\n",
      "k: 18  cv accuracy:  0.8251\n",
      "k: 19  cv accuracy:  0.8183\n",
      "k: 20  cv accuracy:  0.8253\n",
      "k: 21  cv accuracy:  0.8218\n",
      "k: 22  cv accuracy:  0.8152\n",
      "k: 23  cv accuracy:  0.8116\n",
      "k: 24  cv accuracy:  0.8149\n",
      "k: 25  cv accuracy:  0.8183\n",
      "k: 26  cv accuracy:  0.8116\n",
      "k: 27  cv accuracy:  0.8115\n",
      "k: 28  cv accuracy:  0.8082\n",
      "k: 29  cv accuracy:  0.7979\n",
      "k: 30  cv accuracy:  0.8082\n",
      "k: 31  cv accuracy:  0.8117\n",
      "k: 32  cv accuracy:  0.8151\n",
      "k: 33  cv accuracy:  0.8015\n",
      "k: 34  cv accuracy:  0.8083\n",
      "k: 35  cv accuracy:  0.8015\n",
      "k: 36  cv accuracy:  0.8014\n",
      "k: 37  cv accuracy:  0.7844\n",
      "k: 38  cv accuracy:  0.7913\n",
      "k: 39  cv accuracy:  0.7810\n",
      "k: 40  cv accuracy:  0.7947\n",
      "k: 41  cv accuracy:  0.7947\n",
      "k: 42  cv accuracy:  0.7912\n",
      "k: 43  cv accuracy:  0.7809\n",
      "k: 44  cv accuracy:  0.7810\n",
      "k: 45  cv accuracy:  0.7706\n",
      "k: 46  cv accuracy:  0.7672\n",
      "k: 47  cv accuracy:  0.7740\n",
      "k: 48  cv accuracy:  0.7604\n",
      "k: 49  cv accuracy:  0.7604\n",
      "k: 50  cv accuracy:  0.7571\n",
      "k: 51  cv accuracy:  0.7536\n",
      "k: 52  cv accuracy:  0.7400\n",
      "k: 53  cv accuracy:  0.7502\n",
      "k: 54  cv accuracy:  0.7535\n",
      "k: 55  cv accuracy:  0.7467\n",
      "k: 56  cv accuracy:  0.7536\n",
      "k: 57  cv accuracy:  0.7467\n",
      "k: 58  cv accuracy:  0.7435\n",
      "k: 59  cv accuracy:  0.7228\n",
      "k: 60  cv accuracy:  0.7158\n",
      "k: 61  cv accuracy:  0.7159\n",
      "k: 62  cv accuracy:  0.7091\n",
      "k: 63  cv accuracy:  0.7023\n",
      "k: 64  cv accuracy:  0.7092\n",
      "k: 65  cv accuracy:  0.7159\n",
      "k: 66  cv accuracy:  0.7020\n",
      "k: 67  cv accuracy:  0.6883\n",
      "k: 68  cv accuracy:  0.6882\n",
      "k: 69  cv accuracy:  0.6915\n",
      "k: 70  cv accuracy:  0.6813\n",
      "k: 71  cv accuracy:  0.6813\n",
      "k: 72  cv accuracy:  0.6815\n",
      "k: 73  cv accuracy:  0.6814\n",
      "k: 74  cv accuracy:  0.6883\n",
      "k: 75  cv accuracy:  0.6918\n",
      "k: 76  cv accuracy:  0.6782\n",
      "k: 77  cv accuracy:  0.6849\n",
      "k: 78  cv accuracy:  0.6645\n",
      "k: 79  cv accuracy:  0.6848\n",
      "k: 80  cv accuracy:  0.6782\n",
      "k: 81  cv accuracy:  0.6710\n",
      "k: 82  cv accuracy:  0.6644\n",
      "k: 83  cv accuracy:  0.6573\n",
      "k: 84  cv accuracy:  0.6541\n",
      "best_k = 10   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 84  # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,85):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    #print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    NUM_LABELS = len(predicted_labels)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            num_correct += 1  # and we count a match!\n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_model( Features ):\n",
    "\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "    predicted_species = knn_model.predict(our_features)\n",
    "    \n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    return predicted_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a knn classifier, now tuned with a (best) k of 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_tuned = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k!\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Created + trained a knn classifier, now tuned with a (best) k of {best_k}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1.]\n",
      "Actual labels: [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1.]\n",
      "\n",
      "Results on test set:  59 correct out of 74 total.\n",
      "\n",
      "\n",
      "\n",
      "Correct: 59 out of 74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = knn_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\\n\\n\")\n",
    "\n",
    "# Plus, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a 'final' knn classifier, with a (best) k of 10\n"
     ]
    }
   ],
   "source": [
    "knn_model_final = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "knn_model_final.fit(X_all, y_all)                              # here we use ALL the data!\n",
    "print(f\"Created + trained a 'final' knn classifier, with a (best) k of {best_k}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_model( Features, Model ):\n",
    "\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "\n",
    "    # The model's prediction!\n",
    "    predicted_species = Model.predict(our_features)\n",
    "    \n",
    "    # a bit awkward\n",
    "    predicted_species = int(round(predicted_species[0]))  # unpack one element\n",
    "    return predicted_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict 0 from the features [1, 2]\n",
      "I predict 0 from the features [3, 4]\n",
      "I predict 0 from the features [5, 6]\n",
      "I predict 1 from the features [7, 8]\n",
      "I predict 1 from the features [9, 10]\n",
      "I predict 1 from the features [11, 12]\n"
     ]
    }
   ],
   "source": [
    "LoF = [\n",
    "[1,2],\n",
    "[3,4],\n",
    "[5,6],\n",
    "[7,8],\n",
    "[9,10],\n",
    "[11,12],\n",
    "\n",
    "  ]\n",
    "\n",
    "# run on each one:\n",
    "for Features in LoF:\n",
    "    predicted_species = predictive_model( Features, knn_model_final )  # pass in the model, too!\n",
    "    print(f\"I predict {predicted_species} from the features {Features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Final, big-picture question:  \n",
    "+ Which phenomenon, iris-species or birthday-popularity, is more \"modelable\"?\n",
    "+ ... at least, as these two datasets are concerned?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "### Your thoughts... / why...\n",
    "#\n",
    "### In my opinion, I would say that iris-species is more \"modelable\" than birthday-popularity. That is because it is more valuable for us to use models to classify iris-species than birthday-popularity. Models are the tools that help humans identify patterns in the data or phenomenons and do classification works based on that, so the usage of the model would be its largest value. For the iris species, we could use the existing data to train models to know which features each kind of species would have. Then the model could help us classify the species by entering flowers' features. Therefore, we could know more about the patterns of iris and this is its value. On the other hand, it might be useless to build a model to predict the births each day. One of the reasons is that we do not need to predict the unknown day with the model. For example, we do not need to know the birth on December 31 is above or below the average since it would never happen. Another reason is that it is clear to know holidays such as Christmas and Thanksgiving have fewer births than normal days. However, there is no pattern for these holidays, so the model would not be helpful. Therefore, I would say the iris-species is more \"modelable\" than birthday-popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# That's it!  Welcome to the world of model-building workflows!!    \n",
    "#\n",
    "#             Our prediction?  We'll be back for more ML! \n",
    "#\n",
    "\n",
    "#\n",
    "# In fact, the rest of the hw is to run more ML workflows:   (2)Digits, (3)Titanic, (ec)Housing, ...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Regression! For birthdays... kNN Regressor?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
