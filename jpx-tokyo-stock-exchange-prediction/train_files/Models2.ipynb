{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks_cleaned.csv : file read into a pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "# let's read in our stock data...\n",
    "# \n",
    "\n",
    "filename = 'stocks_cleaned.csv'\n",
    "df_tidy = pd.read_csv(filename)      # encoding = \"utf-8\", \"latin1\"\n",
    "print(f\"{filename} : file read into a pandas dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2324923 entries, 0 to 2332530\n",
      "Data columns (total 11 columns):\n",
      "Open            float64\n",
      "High            float64\n",
      "Low             float64\n",
      "Close           float64\n",
      "Volume          int64\n",
      "Target          float64\n",
      "Year            int64\n",
      "Month           int64\n",
      "Day             int64\n",
      "twoclass        int64\n",
      "multiclasses    int64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 212.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_tidy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>twoclass</th>\n",
       "      <th>multiclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low   Close   Volume    Target  Year  Month  Day  \\\n",
       "0  2734.0  2755.0  2730.0  2742.0    31400  0.000730  2017      1    4   \n",
       "1   568.0   576.0   563.0   571.0  2798500  0.012324  2017      1    4   \n",
       "2  3150.0  3210.0  3140.0  3210.0   270800  0.006154  2017      1    4   \n",
       "3  1510.0  1550.0  1510.0  1550.0    11300  0.011053  2017      1    4   \n",
       "4  3270.0  3350.0  3270.0  3330.0   150800  0.003026  2017      1    4   \n",
       "\n",
       "   twoclass  multiclasses  \n",
       "0         1             5  \n",
       "1         1             7  \n",
       "2         1             6  \n",
       "3         1             7  \n",
       "4         1             5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Classes Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>twoclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low   Close   Volume  Year  Month  Day  twoclass\n",
       "0  2734.0  2755.0  2730.0  2742.0    31400  2017      1    4         1\n",
       "1   568.0   576.0   563.0   571.0  2798500  2017      1    4         1\n",
       "2  3150.0  3210.0  3140.0  3210.0   270800  2017      1    4         1\n",
       "3  1510.0  1550.0  1510.0  1550.0    11300  2017      1    4         1\n",
       "4  3270.0  3350.0  3270.0  3330.0   150800  2017      1    4         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# All of the columns need to be numeric, we'll drop Target and multiclasses\n",
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1 = df_tidy.drop(['Target', 'multiclasses'], axis=COLUMN )\n",
    "df_model1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL_INDEX is {'Open': 0, 'High': 1, 'Low': 2, 'Close': 3, 'Volume': 4, 'Year': 5, 'Month': 6, 'Day': 7, 'multiclasses': 8}\n",
      "\n",
      "\n",
      "negative maps to 0\n",
      "positive maps to 1\n"
     ]
    }
   ],
   "source": [
    "# let's create a dictionary to look up any column index by name\n",
    "COLUMNS = df_model1.columns\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX is {COL_INDEX}\\n\\n\")\n",
    "\n",
    "\n",
    "#\n",
    "# and our \"class\" names\n",
    "#\n",
    "\n",
    "\n",
    "SPECIES = ['negative', 'positive']   # int to str\n",
    "SPECIES_INDEX = {'negative':0,'positive':1}  # str to int\n",
    "\n",
    "# Let's try it out...\n",
    "for name in SPECIES:\n",
    "    print(f\"{name} maps to {SPECIES_INDEX[name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.734e+03 2.755e+03 2.730e+03 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " [5.680e+02 5.760e+02 5.630e+02 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " [3.150e+03 3.210e+03 3.140e+03 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " ...\n",
      " [1.690e+03 1.690e+03 1.645e+03 ... 1.200e+01 3.000e+00 0.000e+00]\n",
      " [2.388e+03 2.396e+03 2.380e+03 ... 1.200e+01 3.000e+00 1.000e+00]\n",
      " [6.900e+02 7.110e+02 6.860e+02 ... 1.200e+01 3.000e+00 1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's convert our dataframe to a numpy array, named A\n",
    "#\n",
    "A = df_model1.to_numpy()   \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.734e+03 2.755e+03 2.730e+03 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " [5.680e+02 5.760e+02 5.630e+02 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " [3.150e+03 3.210e+03 3.140e+03 ... 1.000e+00 4.000e+00 1.000e+00]\n",
      " ...\n",
      " [1.690e+03 1.690e+03 1.645e+03 ... 1.200e+01 3.000e+00 0.000e+00]\n",
      " [2.388e+03 2.396e+03 2.380e+03 ... 1.200e+01 3.000e+00 1.000e+00]\n",
      " [6.900e+02 7.110e+02 6.860e+02 ... 1.200e+01 3.000e+00 1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's make sure it's all floating-point (here, it already is, but in other datasets it might not be)\n",
    "#\n",
    "A = A.astype('float64')  \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 2324923 rows and 9 cols\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# nice to have NUM_ROWS and NUM_COLS around\n",
    "#\n",
    "NUM_ROWS, NUM_COLS = A.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower #42 is [3.430e+02 3.490e+02 3.430e+02 3.480e+02 7.410e+05 2.017e+03 1.000e+00\n",
      " 4.000e+00 0.000e+00]\n",
      "  Its Open is 343.0\n",
      "  Its High is 349.0\n",
      "  Its Low is 343.0\n",
      "  Its Close is 348.0\n",
      "  Its Volume is 741000.0\n",
      "  Its Year is 2017.0\n",
      "  Its Month is 1.0\n",
      "  Its Day is 4.0\n",
      "  Its twoclass is 0.0\n",
      "  Its class is negative (i.e., 0)\n"
     ]
    }
   ],
   "source": [
    "# let's use all of our variables, to reinforce that we have\n",
    "# (1) names...\n",
    "# (2) access and control...\n",
    "\n",
    "# choose a row index, n:\n",
    "n = 42\n",
    "print(f\"flower #{n} is {A[n]}\")\n",
    "\n",
    "for i in range(len(COLUMNS)):\n",
    "    colname = COLUMNS[i]\n",
    "    value = A[n][i]\n",
    "    print(f\"  Its {colname} is {value}\")\n",
    "\n",
    "species_index = COL_INDEX['twoclass']\n",
    "species_num = int(round(A[n][species_index]))\n",
    "species = SPECIES[species_num]\n",
    "print(f\"  Its class is {species} (i.e., {species_num})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n",
      "y_all (just the labels/species)   are \n",
      " [1. 1. 1. ... 0. 1. 1.]\n",
      "X_all (just the features, first few rows) are \n",
      " [[2.7340e+03 2.7550e+03 2.7300e+03 2.7420e+03 3.1400e+04 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [5.6800e+02 5.7600e+02 5.6300e+02 5.7100e+02 2.7985e+06 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [3.1500e+03 3.2100e+03 3.1400e+03 3.2100e+03 2.7080e+05 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [1.5100e+03 1.5500e+03 1.5100e+03 1.5500e+03 1.1300e+04 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [3.2700e+03 3.3500e+03 3.2700e+03 3.3300e+03 1.5080e+05 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "#\n",
    "# we could do this at the data-frame level, too!\n",
    "#\n",
    "\n",
    "X_all = A[:,0:8]  # X (features) ... is all rows except column 8\n",
    "y_all = A[:,8]    # y (labels) ... is all rows, column 8 only\n",
    "\n",
    "print(f\"y_all (just the labels/species)   are \\n {y_all}\")\n",
    "print(f\"X_all (just the features, first few rows) are \\n {X_all[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1859938 rows;  testing with 464985 rows\n",
      "\n",
      "Held-out data... (testing data: 464985)\n",
      "y_test: [0. 0. 1. ... 1. 1. 1.]\n",
      "\n",
      "X_test (few rows): [[1.980e+03 1.980e+03 1.951e+03 1.956e+03 7.100e+04 2.019e+03 6.000e+00\n",
      "  2.400e+01]\n",
      " [1.341e+03 1.378e+03 1.331e+03 1.363e+03 5.425e+05 2.018e+03 8.000e+00\n",
      "  8.000e+00]\n",
      " [2.180e+03 2.195e+03 2.148e+03 2.184e+03 4.860e+04 2.021e+03 8.000e+00\n",
      "  2.000e+01]\n",
      " [3.425e+03 3.445e+03 3.275e+03 3.295e+03 4.690e+05 2.021e+03 5.000e+00\n",
      "  1.200e+01]\n",
      " [2.337e+03 2.438e+03 2.301e+03 2.438e+03 2.803e+05 2.020e+03 3.000e+00\n",
      "  3.000e+01]]\n",
      "\n",
      "Data used for modeling... (training data: 1859938)\n",
      "y_train: [1. 1. 1. ... 0. 0. 1.]\n",
      "\n",
      "X_train (few rows): [[3.6900e+02 3.8500e+02 3.6900e+02 3.8100e+02 8.9090e+05 2.0200e+03\n",
      "  9.0000e+00 8.0000e+00]\n",
      " [2.0500e+03 2.0520e+03 1.9780e+03 1.9810e+03 1.2150e+05 2.0180e+03\n",
      "  1.0000e+00 3.0000e+01]\n",
      " [8.5700e+02 8.5700e+02 8.4600e+02 8.5000e+02 1.4980e+05 2.0170e+03\n",
      "  8.0000e+00 3.0000e+00]\n",
      " [4.6100e+02 4.6700e+02 4.6000e+02 4.6000e+02 8.6761e+06 2.0170e+03\n",
      "  9.0000e+00 1.4000e+01]\n",
      " [2.7000e+03 2.7000e+03 2.6700e+03 2.6800e+03 7.0000e+02 2.0180e+03\n",
      "  1.0000e+01 1.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\\n\")\n",
    "print(f\"X_test (few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\\n\")\n",
    "print(f\"X_train (few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks_cleaned_test.csv : file read into a pandas dataframe.\n",
      "[[2.982e+03 2.982e+03 2.965e+03 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " [5.920e+02 5.990e+02 5.880e+02 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " [2.368e+03 2.388e+03 2.360e+03 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.600e+03 1.622e+03 1.600e+03 ... 2.000e+00 2.800e+01 1.000e+00]\n",
      " [2.568e+03 2.568e+03 2.540e+03 ... 2.000e+00 2.800e+01 0.000e+00]\n",
      " [7.310e+02 7.370e+02 7.260e+02 ... 2.000e+00 2.800e+01 0.000e+00]]\n",
      "[[2.982e+03 2.982e+03 2.965e+03 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " [5.920e+02 5.990e+02 5.880e+02 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " [2.368e+03 2.388e+03 2.360e+03 ... 1.200e+01 6.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.600e+03 1.622e+03 1.600e+03 ... 2.000e+00 2.800e+01 1.000e+00]\n",
      " [2.568e+03 2.568e+03 2.540e+03 ... 2.000e+00 2.800e+01 0.000e+00]\n",
      " [7.310e+02 7.370e+02 7.260e+02 ... 2.000e+00 2.800e+01 0.000e+00]]\n",
      "\n",
      "The dataset has 111716 rows and 9 cols\n",
      "+++ Start of data definitions +++\n",
      "\n",
      "y_all (just the labels/species)   are \n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      "X_all (just the features, first few rows) are \n",
      " [[2.9820e+03 2.9820e+03 2.9650e+03 2.9710e+03 8.9000e+03 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [5.9200e+02 5.9900e+02 5.8800e+02 5.8900e+02 1.3608e+06 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [2.3680e+03 2.3880e+03 2.3600e+03 2.3770e+03 1.2590e+05 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [1.2300e+03 1.2390e+03 1.2240e+03 1.2240e+03 8.1100e+04 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [1.3390e+03 1.3720e+03 1.3390e+03 1.3510e+03 6.2000e+03 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Also read the extra testing data\n",
    "\n",
    "filename_test = 'stocks_cleaned_test.csv'\n",
    "df_tidy_test = pd.read_csv(filename_test)      # encoding = \"utf-8\", \"latin1\"\n",
    "print(f\"{filename_test} : file read into a pandas dataframe.\")\n",
    "\n",
    "#\n",
    "# All of the columns need to be numeric, we'll drop irisname\n",
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1_test = df_tidy_test.drop(['Target', 'multiclasses'], axis=COLUMN )\n",
    "df_model1_test.head()\n",
    "\n",
    "#\n",
    "# let's convert our dataframe to a numpy array, named B\n",
    "#\n",
    "B = df_model1_test.to_numpy()   \n",
    "print(B)\n",
    "\n",
    "#\n",
    "# let's make sure it's all floating-point (here, it already is, but in other datasets it might not be)\n",
    "#\n",
    "B = B.astype('float64')  \n",
    "print(B)\n",
    "\n",
    "#\n",
    "# nice to have NUM_ROWS and NUM_COLS around\n",
    "#\n",
    "NUM_ROWS, NUM_COLS = B.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")\n",
    "\n",
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "#\n",
    "# we could do this at the data-frame level, too!\n",
    "#\n",
    "\n",
    "X_all_test = B[:,0:8]  # X (features) ... is all rows except column 8\n",
    "y_all_test = B[:,8]    # y (labels) ... is all rows, column 8 only\n",
    "\n",
    "print(f\"y_all (just the labels/species)   are \\n {y_all_test}\")\n",
    "print(f\"X_all (just the features, first few rows) are \\n {X_all_test[0:5]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50189791 0.50092476 0.50309419 0.50298532 0.50078632]\n",
      "k:  1  cv accuracy:  0.5019\n",
      "[0.51137402 0.50967773 0.51144929 0.51014955 0.51076516]\n",
      "k:  2  cv accuracy:  0.5107\n",
      "[0.50272589 0.50192748 0.50260223 0.50263853 0.50243154]\n",
      "k:  3  cv accuracy:  0.5025\n",
      "[0.50983096 0.50946267 0.50875566 0.50831077 0.5091764 ]\n",
      "k:  4  cv accuracy:  0.5091\n",
      "[0.50326086 0.50271783 0.50246782 0.50181324 0.50236971]\n",
      "k:  5  cv accuracy:  0.5025\n",
      "[0.50868039 0.50789542 0.50780133 0.50812528 0.5081683 ]\n",
      "k:  6  cv accuracy:  0.5081\n",
      "[0.50297859 0.50342484 0.50276891 0.50198797 0.50277026]\n",
      "k:  7  cv accuracy:  0.5028\n",
      "[0.5076696  0.50710507 0.50841694 0.50660641 0.50838336]\n",
      "k:  8  cv accuracy:  0.5076\n",
      "[0.50262912 0.5032286  0.50365603 0.50212239 0.50360362]\n",
      "k:  9  cv accuracy:  0.5030\n",
      "[0.50685237 0.50779595 0.5076696  0.50598274 0.50777312]\n",
      "k: 10  cv accuracy:  0.5072\n",
      "[0.50216942 0.50373937 0.50415605 0.50251218 0.50317081]\n",
      "k: 11  cv accuracy:  0.5031\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-038df34f75ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mknn_cv_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# build knn_model for every k!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mknn_cv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;31m# cv=5 means 80/20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# just to see the five scores...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0maverage_cv_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean() is numpy's built-in average function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(a, axis, nan_policy)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0mmodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mmodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mnewshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_it\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# we also use \"cross validation\"\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 84  # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,20):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "# assign best value of k to best_k\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_k = k      # at the moment this is incorrect   \n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a knn classifier, now tuned with a (best) k of 2\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# With the best k, we build and train a new model:\n",
    "#\n",
    "# Now, we use best_k instead of the original, randomly-guessed value    \n",
    "#\n",
    "best_k = 2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_tuned = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k!\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Created + trained a knn classifier, now tuned with a (best) k of {best_k}\")  \n",
    "\n",
    "# How does it do?!  The next cell will show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. ... 1. 0. 0.]\n",
      "Actual labels: [0. 0. 1. ... 1. 1. 1.]\n",
      "\n",
      "Results on test set:  237946 correct out of 464985 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = knn_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a 'final' knn classifier, with a (best) k of 2\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned knn to use the \"best\" value of k...\n",
    "#\n",
    "# And, we should now use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "knn_model_final.fit(X_all, y_all)                              # here we use ALL the data!\n",
    "print(f\"Created + trained a 'final' knn classifier, with a (best) k of {best_k}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 0. 0. ... 0. 0. 0.]\n",
      "Actual labels: [0. 0. 0. ... 1. 0. 0.]\n",
      "\n",
      "Results on test set:  57950 correct out of 111716 total, which is  0.5187.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = knn_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "import pickle\n",
    "# save the classifier\n",
    "with open('knn_model_final.pkl', 'wb') as fid:\n",
    "    pickle.dump(knn_model_final, fid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it again\n",
    "\n",
    "with open('knn_model_final.pkl', 'rb') as fid:\n",
    "    testmodel = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.5189\n",
      "depth:  2  cv accuracy:  0.5221\n",
      "depth:  3  cv accuracy:  0.5247\n",
      "depth:  4  cv accuracy:  0.5314\n",
      "depth:  5  cv accuracy:  0.5389\n",
      "depth:  6  cv accuracy:  0.5469\n",
      "depth:  7  cv accuracy:  0.5569\n",
      "depth:  8  cv accuracy:  0.5698\n",
      "depth:  9  cv accuracy:  0.5878\n",
      "depth: 10  cv accuracy:  0.6072\n",
      "depth: 11  cv accuracy:  0.6231\n",
      "depth: 12  cv accuracy:  0.6393\n",
      "depth: 13  cv accuracy:  0.6512\n",
      "depth: 14  cv accuracy:  0.6601\n",
      "depth: 15  cv accuracy:  0.6663\n",
      "depth: 16  cv accuracy:  0.6693\n",
      "depth: 17  cv accuracy:  0.6696\n",
      "depth: 18  cv accuracy:  0.6689\n",
      "depth: 19  cv accuracy:  0.6669\n",
      "\n",
      "best_depth = 17 is our choice for an underfitting/overfitting balance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# To compare different tree-depths, we use cross validation\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "best_d = 1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for d in range(1,20):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   # for each depth, d\n",
    "    cv_scores = cross_val_score( cv_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "    # print(cv_scores)  # we usually don't want to see the five individual scores \n",
    "    average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_d = d\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth\n",
    "best_depth = best_d   # may have to hand-tune this, depending on what happens...\n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for an underfitting/overfitting balance.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a DT classifier with max depth = 17\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# this time, with the best depth, best_d, found by cross-validation model tuning:\n",
    "#\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_tuned = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 1. ... 0. 0. 0.]\n",
      "Actual  labels  : [0. 0. 1. ... 1. 1. 1.]\n",
      "\n",
      "Results on test set:  312814 correct out of 464985 total, which is  0.6727.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This cell will \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well our model does on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set:\n",
    "\n",
    "# the function knn_model.predict is the instantiation of our model\n",
    "# it's what runs the k-nearest-neighbors algorithm:\n",
    "predicted_labels = dtree_model_tuned.predict(X_test)   \n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a 'final' DT classifier with max depth = 17\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our DT to use the \"best\" depth...\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_final = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_final.fit(X_all, y_all)                              # yay!  trained!\n",
    "print(\"Created and trained a 'final' DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 1. 1. ... 0. 0. 1.]\n",
      "Actual labels: [0. 0. 0. ... 1. 0. 0.]\n",
      "\n",
      "Results on test set:  52676 correct out of 111716 total, which is  0.4715.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = dtree_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03773508 0.03849803 0.03710759 0.03749145 0.11714993 0.20678224\n",
      " 0.24853093 0.27670476]\n",
      "\n",
      "Feature         Open has    3.77% of the decision-making importance.\n",
      "Feature         High has    3.85% of the decision-making importance.\n",
      "Feature          Low has    3.71% of the decision-making importance.\n",
      "Feature        Close has    3.75% of the decision-making importance.\n",
      "Feature       Volume has   11.71% of the decision-making importance.\n",
      "Feature         Year has   20.68% of the decision-making importance.\n",
      "Feature        Month has   24.85% of the decision-making importance.\n",
      "Feature          Day has   27.67% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "print(dtree_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = dtree_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "\n",
    "with open('dtree_model_final.pkl', 'wb') as fid:\n",
    "    pickle.dump(dtree_model_final, fid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  10 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   21.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   22.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   20.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  30 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  50 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  10 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   39.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   40.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   39.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   43.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   41.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  30 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  50 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  10 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   55.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   58.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   55.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  30 cv accuracy:  0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  50 cv accuracy:  0.5190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   30.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   24.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  10 cv accuracy:  0.5226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  30 cv accuracy:  0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  50 cv accuracy:  0.5214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   32.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   33.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   34.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   37.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   37.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  10 cv accuracy:  0.5289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  30 cv accuracy:  0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  50 cv accuracy:  0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   40.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   42.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   39.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   40.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   40.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  6 ntrees:  10 cv accuracy:  0.5346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  6 ntrees:  30 cv accuracy:  0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-adf52ce33a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                         \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntrees\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                         verbose=1)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrforest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 5 means 80/20 split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0maverage_cv_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# more likely, only their average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# So, to compare different parameters, let's use cv\n",
    "#\n",
    "from sklearn import ensemble  # for random forests, an ensemble classifier\n",
    "\n",
    "best_d = 1\n",
    "best_ntrees = 10   \n",
    "best_accuracy = 0\n",
    "\n",
    "for d in range(1,10):\n",
    "    for ntrees in range(10,60,20):\n",
    "        rforest_model = ensemble.RandomForestClassifier(max_depth=d, \n",
    "                                                        n_estimators=ntrees,\n",
    "                                                        verbose=1)\n",
    "        cv_scores = cross_val_score( rforest_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "        average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "        print(f\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "        if average_cv_accuracy > best_accuracy:\n",
    "            best_d = d\n",
    "            best_ntrees = ntrees\n",
    "            best_accuracy = average_cv_accuracy\n",
    "\n",
    "\n",
    "best_depth = best_d   \n",
    "best_num_trees = best_ntrees\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"best_depth: {best_depth} and best_num_trees: {best_num_trees} are our choices.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=6 and ntrees=30\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "\n",
    "best_depth = 6\n",
    "best_num_trees = 30\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_tuned = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. ... 0. 0. 0.]\n",
      "Actual  labels  : [0. 0. 1. ... 1. 1. 1.]\n",
      "\n",
      "Results on test set:  248301 correct out of 464985 total.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is our \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = rforest_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=6 and ntrees=30\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our RF to use the \"best\" parameters\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_final = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_final.fit(X_all, y_all)              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 1. 1. ... 0. 0. 1.]\n",
      "Actual labels: [0. 0. 0. ... 1. 0. 0.]\n",
      "\n",
      "Results on test set:  52676 correct out of 111716 total, which is  0.4715.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = dtree_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03880944 0.0315299  0.05595399 0.05863804 0.0522319  0.16033798\n",
      " 0.234926   0.36757276]\n",
      "\n",
      "Feature         Open has    3.88% of the decision-making importance.\n",
      "Feature         High has    3.15% of the decision-making importance.\n",
      "Feature          Low has    5.60% of the decision-making importance.\n",
      "Feature        Close has    5.86% of the decision-making importance.\n",
      "Feature       Volume has    5.22% of the decision-making importance.\n",
      "Feature         Year has   16.03% of the decision-making importance.\n",
      "Feature        Month has   23.49% of the decision-making importance.\n",
      "Feature          Day has   36.76% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# feature importances are often even more \"important\" than predictions...\n",
    "#\n",
    "#    Random forests can provide a much \"smoother\" measure of feature importance, since\n",
    "#                   they integrate over so many individual models (each tree)\n",
    "#\n",
    "#    That is, it's much less likely that a feature will have 0% importance, \n",
    "#             unless it never varies\n",
    "#\n",
    "\n",
    "print(rforest_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = rforest_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "\n",
    "with open('rforest_model_final.pkl', 'wb') as fid:\n",
    "    pickle.dump(rforest_model_final, fid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[-0.62228159 -0.61949894 -0.62053342 -0.6189016   0.05002699  0.71498637\n",
      "  0.74171276 -0.902306  ] -> ?     1    \n",
      "[-0.15200495 -0.15853714 -0.16484816 -0.17120035 -0.14541927 -0.70714375\n",
      " -1.6213479   1.61890759] -> ?     1    \n",
      "[-0.48575869 -0.48898066 -0.48544214 -0.48766917 -0.13823038 -1.41820882\n",
      "  0.44633018 -1.47530909] -> ?     1    \n",
      "[-0.59654367 -0.59682416 -0.59476129 -0.59679635  2.02765657 -1.41820882\n",
      "  0.74171276 -0.2147023 ] -> ?     1    \n",
      "[ 0.02983909  0.02064898  0.03113331  0.02438913 -0.1761054  -0.70714375\n",
      "  1.03709534 -0.67310477] -> ?     0    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) # scale!\n",
    "X_test_scaled = scaler.transform(X_test) # scale!\n",
    "\n",
    "y_train_scaled = y_train  # the predicted/desired labels are not scaled\n",
    "y_test_scaled = y_test  # not using the scaler\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_train_scaled[0:5,:],y_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++  TRAINING:  begin  +++++++++++++++\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.69047908\n",
      "Iteration 2, loss = 0.68529552\n",
      "Iteration 3, loss = 0.68079946\n",
      "Iteration 4, loss = 0.67815136\n",
      "Iteration 5, loss = 0.67574658\n",
      "Iteration 6, loss = 0.67421764\n",
      "Iteration 7, loss = 0.67273740\n",
      "Iteration 8, loss = 0.67173017\n",
      "Iteration 9, loss = 0.67071202\n",
      "Iteration 10, loss = 0.67018057\n",
      "Iteration 11, loss = 0.66997090\n",
      "Iteration 12, loss = 0.66966905\n",
      "Iteration 13, loss = 0.66993277\n",
      "Iteration 14, loss = 0.66934411\n",
      "Iteration 15, loss = 0.66948981\n",
      "Iteration 16, loss = 0.66925607\n",
      "Iteration 17, loss = 0.66916500\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 18, loss = 0.66171907\n",
      "Iteration 19, loss = 0.66094575\n",
      "Iteration 20, loss = 0.66099653\n",
      "Iteration 21, loss = 0.66070045\n",
      "Iteration 22, loss = 0.66077645\n",
      "Iteration 23, loss = 0.66069533\n",
      "Iteration 24, loss = 0.66051355\n",
      "Iteration 25, loss = 0.66079183\n",
      "Iteration 26, loss = 0.66036189\n",
      "Iteration 27, loss = 0.66035425\n",
      "Iteration 28, loss = 0.66039319\n",
      "Iteration 29, loss = 0.66028082\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 30, loss = 0.65830692\n",
      "Iteration 31, loss = 0.65795394\n",
      "Iteration 32, loss = 0.65790122\n",
      "Iteration 33, loss = 0.65788114\n",
      "Iteration 34, loss = 0.65785701\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 35, loss = 0.65734253\n",
      "Iteration 36, loss = 0.65729067\n",
      "Iteration 37, loss = 0.65729205\n",
      "Iteration 38, loss = 0.65728086\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 39, loss = 0.65716799\n",
      "Iteration 40, loss = 0.65715355\n",
      "Iteration 41, loss = 0.65715015\n",
      "Iteration 42, loss = 0.65715069\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 43, loss = 0.65712369\n",
      "Iteration 44, loss = 0.65712142\n",
      "Iteration 45, loss = 0.65711989\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 46, loss = 0.65711316\n",
      "Iteration 47, loss = 0.65711290\n",
      "Iteration 48, loss = 0.65711271\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 49, loss = 0.65711113\n",
      "Iteration 50, loss = 0.65711110\n",
      "Iteration 51, loss = 0.65711107\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 52, loss = 0.65711074\n",
      "Iteration 53, loss = 0.65711073\n",
      "Iteration 54, loss = 0.65711073\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "\n",
      "++++++++++  TRAINING:   end  +++++++++++++++\n",
      "The analog prediction error (the loss) is 0.657110725026624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#\n",
    "# Here's where you can change the number of hidden layers\n",
    "# and number of neurons!\n",
    "#\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(16,8,4),  # 8 input ->  -> 1 output\n",
    "                    max_iter=100,      # how many times to train\n",
    "                    activation=\"tanh\", # the \"activation function\" input -> output\n",
    "                    solver='sgd',      # the algorithm for optimizing weights\n",
    "                    verbose=True,      # False to \"mute\" the training\n",
    "                    shuffle=True,      # reshuffle the training epochs?\n",
    "                    random_state=None, # set for reproduceability\n",
    "                    learning_rate_init=.1,       # learning rate: % of error to backprop\n",
    "                    learning_rate = 'adaptive')  # soften feedback as it converges\n",
    "\n",
    "# documentation:\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n",
    "#     Try verbose / activation \"relu\" / other network sizes ...\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_classifier.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"\\n++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "print(f\"The analog prediction error (the loss) is {nn_classifier.loss_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 1087090 out of 1859938, which is  0.5845.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# how did it do on the testing data?\n",
    "#\n",
    "\n",
    "#\n",
    "# which one do we want: classifier or regressor?\n",
    "#\n",
    "\n",
    "def ascii_table_for_classifier(Xsc,y,nn,scaler):\n",
    "    \"\"\" a table including predictions using nn.predict \"\"\"\n",
    "    predictions = nn.predict(Xsc)            # all predictions\n",
    "    prediction_probs = nn.predict_proba(Xsc) # all prediction probabilities\n",
    "    Xpr = scaler.inverse_transform(Xsc)      # Xpr is the \"X to print\": unscaled data!\n",
    "    # count correct\n",
    "    num_correct = 0\n",
    "    # printing\n",
    "    # print(f\"{'input ':>28s} -> {'pred':^6s} {'des.':^6s}\") \n",
    "    for i in range(len(y)):\n",
    "        pred = predictions[i]\n",
    "        pred_probs = prediction_probs[i,:]\n",
    "        desired = y[i]\n",
    "        if pred != desired: result = \"  incorrect: \" + str(pred_probs)\n",
    "        else: result = \"  correct\"; num_correct += 1\n",
    "        # Xpr = Xsc  # if you want to see the scaled versions\n",
    "        #print(f\"{Xpr[i,:]!s:>28s} -> {pred:^6.0f} {desired:^6.0f} {result:^10s}\") \n",
    "    print(f\"\\ncorrect predictions: {num_correct} out of {len(y)}, which is {num_correct/len(y):7.4f}.\")\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "# let's see how it did on the test data (also the training data!)\n",
    "#\n",
    "ascii_table_for_classifier(X_train_scaled,\n",
    "                           y_train_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler)   \n",
    "#\n",
    "# other things...\n",
    "#\n",
    "if False:  # do we want to see all of the parameters?\n",
    "    nn = nn_classifier  # less to type?\n",
    "    print(\"\\n\\n+++++ parameters, weights, etc. +++++\\n\")\n",
    "    print(f\"\\nweights/coefficients:\\n\")\n",
    "    for wts in nn.coefs_:\n",
    "        print(wts)\n",
    "    print(f\"\\nintercepts: {nn.intercepts_}\")\n",
    "    print(f\"\\nall parameters: {nn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 272105 out of 464985, which is  0.5852.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's see how it did on the training data \n",
    "#\n",
    "ascii_table_for_classifier(X_test_scaled,\n",
    "                           y_test_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler)   \n",
    "#\n",
    "# other things...\n",
    "#\n",
    "if False:  # do we want to see all of the parameters?\n",
    "    nn = nn_classifier  # less to type?\n",
    "    print(\"\\n\\n+++++ parameters, weights, etc. +++++\\n\")\n",
    "    print(f\"\\nweights/coefficients:\\n\")\n",
    "    for wts in nn.coefs_:\n",
    "        print(wts)\n",
    "    print(f\"\\nintercepts: {nn.intercepts_}\")\n",
    "    print(f\"\\nall parameters: {nn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[ 0.10873142  0.09862812  0.11468033  0.10581479 -0.1740224   1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     0    \n",
      "[-0.5598951  -0.56032328 -0.55851038 -0.56070044  0.16939298  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     0    \n",
      "[-0.06304125 -0.06562582 -0.05666186 -0.0603943  -0.14430156  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     0    \n",
      "[-0.38140819 -0.38334934 -0.37838867 -0.38301901 -0.15568185  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     0    \n",
      "[-0.35091434 -0.34657195 -0.3458195  -0.34748272 -0.17470827  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     1    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_all_test_scaled = scaler.transform(X_all_test) # scale!\n",
    "\n",
    "y_all_test_scaled = y_all_test  # the predicted/desired labels are not scaled\n",
    "\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_all_test_scaled[0:5,:], y_all_test_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 53380 out of 111716, which is  0.4778.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's see how it did on the extra test data (also the training data!)\n",
    "#\n",
    "ascii_table_for_classifier(X_all_test_scaled,\n",
    "                           y_all_test_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[ 0.03899406  0.03549253  0.04776377  0.04137425 -0.16919196 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     1    \n",
      "[-0.56650895 -0.56654721 -0.56551035 -0.5656374   0.53716061 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     1    \n",
      "[ 0.15528642  0.16120528  0.16379625  0.17222706 -0.10808076 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     1    \n",
      "[-0.30317384 -0.29743904 -0.29750362 -0.29190898 -0.17432285 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     1    \n",
      "[ 0.1888323   0.19988612  0.20058704  0.20577906 -0.13871294 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     1    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_all)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_all)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_all_scaled = scaler.transform(X_all) # scale!\n",
    "y_all_scaled = y_all  # the predicted/desired labels are not scaled\n",
    "\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_all_scaled[0:5,:], y_all_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++  TRAINING:  begin  +++++++++++++++\n",
      "\n",
      "\n",
      "Iteration 1, loss = 0.69023708\n",
      "Iteration 2, loss = 0.68487740\n",
      "Iteration 3, loss = 0.67920752\n",
      "Iteration 4, loss = 0.67662052\n",
      "Iteration 5, loss = 0.67513929\n",
      "Iteration 6, loss = 0.67394997\n",
      "Iteration 7, loss = 0.67301284\n",
      "Iteration 8, loss = 0.67148129\n",
      "Iteration 9, loss = 0.67113311\n",
      "Iteration 10, loss = 0.67100568\n",
      "Iteration 11, loss = 0.67057704\n",
      "Iteration 12, loss = 0.67042704\n",
      "Iteration 13, loss = 0.67008495\n",
      "Iteration 14, loss = 0.67077283\n",
      "Iteration 15, loss = 0.67068042\n",
      "Iteration 16, loss = 0.67102886\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 17, loss = 0.66263190\n",
      "Iteration 18, loss = 0.66103834\n",
      "Iteration 19, loss = 0.66093542\n",
      "Iteration 20, loss = 0.66165592\n",
      "Iteration 21, loss = 0.66094598\n",
      "Iteration 22, loss = 0.66092475\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 23, loss = 0.65842917\n",
      "Iteration 24, loss = 0.65805595\n",
      "Iteration 25, loss = 0.65789842\n",
      "Iteration 26, loss = 0.65787098\n",
      "Iteration 27, loss = 0.65777068\n",
      "Iteration 28, loss = 0.65770854\n",
      "Iteration 29, loss = 0.65766727\n",
      "Iteration 30, loss = 0.65764160\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 31, loss = 0.65704437\n",
      "Iteration 32, loss = 0.65700462\n",
      "Iteration 33, loss = 0.65699334\n",
      "Iteration 34, loss = 0.65697336\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 35, loss = 0.65685358\n",
      "Iteration 36, loss = 0.65684106\n",
      "Iteration 37, loss = 0.65683771\n",
      "Iteration 38, loss = 0.65683850\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 39, loss = 0.65680590\n",
      "Iteration 40, loss = 0.65680400\n",
      "Iteration 41, loss = 0.65680300\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 42, loss = 0.65679579\n",
      "Iteration 43, loss = 0.65679532\n",
      "Iteration 44, loss = 0.65679510\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 45, loss = 0.65679338\n",
      "Iteration 46, loss = 0.65679335\n",
      "Iteration 47, loss = 0.65679332\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 48, loss = 0.65679296\n",
      "Iteration 49, loss = 0.65679296\n",
      "Iteration 50, loss = 0.65679295\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "\n",
      "++++++++++  TRAINING:   end  +++++++++++++++\n",
      "The analog prediction error (the loss) is 0.657110725026624\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here's where you can change the number of hidden layers\n",
    "# and number of neurons!\n",
    "#\n",
    "nn_classifier_final = MLPClassifier(hidden_layer_sizes=(16,8,4),  # 8 input ->  -> 1 output\n",
    "                    max_iter=100,      # how many times to train\n",
    "                    activation=\"tanh\", # the \"activation function\" input -> output\n",
    "                    solver='sgd',      # the algorithm for optimizing weights\n",
    "                    verbose=True,      # False to \"mute\" the training\n",
    "                    shuffle=True,      # reshuffle the training epochs?\n",
    "                    random_state=None, # set for reproduceability\n",
    "                    learning_rate_init=.1,       # learning rate: % of error to backprop\n",
    "                    learning_rate = 'adaptive')  # soften feedback as it converges\n",
    "\n",
    "# documentation:\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n",
    "#     Try verbose / activation \"relu\" / other network sizes ...\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_classifier_final.fit(X_all_scaled, y_all_scaled)\n",
    "print(\"\\n++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "print(f\"The analog prediction error (the loss) is {nn_classifier.loss_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 56830 out of 111716, which is  0.5087.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's see how it did on the extra test data \n",
    "#\n",
    "ascii_table_for_classifier(X_all_test_scaled,\n",
    "                           y_all_test_scaled,\n",
    "                           nn_classifier_final,\n",
    "                           scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "\n",
    "with open('nn_classifier_final.pkl', 'wb') as fid:\n",
    "    pickle.dump(nn_classifier_final, fid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Classes Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>multiclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low   Close   Volume  Year  Month  Day  multiclasses\n",
       "0  2734.0  2755.0  2730.0  2742.0    31400  2017      1    4             5\n",
       "1   568.0   576.0   563.0   571.0  2798500  2017      1    4             7\n",
       "2  3150.0  3210.0  3140.0  3210.0   270800  2017      1    4             6\n",
       "3  1510.0  1550.0  1510.0  1550.0    11300  2017      1    4             7\n",
       "4  3270.0  3350.0  3270.0  3330.0   150800  2017      1    4             5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# All of the columns need to be numeric, we'll drop Target and twoclass\n",
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1 = df_tidy.drop(['Target', 'twoclass'], axis=COLUMN )\n",
    "df_model1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.734e+03 2.755e+03 2.730e+03 ... 1.000e+00 4.000e+00 5.000e+00]\n",
      " [5.680e+02 5.760e+02 5.630e+02 ... 1.000e+00 4.000e+00 7.000e+00]\n",
      " [3.150e+03 3.210e+03 3.140e+03 ... 1.000e+00 4.000e+00 6.000e+00]\n",
      " ...\n",
      " [1.690e+03 1.690e+03 1.645e+03 ... 1.200e+01 3.000e+00 4.000e+00]\n",
      " [2.388e+03 2.396e+03 2.380e+03 ... 1.200e+01 3.000e+00 6.000e+00]\n",
      " [6.900e+02 7.110e+02 6.860e+02 ... 1.200e+01 3.000e+00 8.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's convert our dataframe to a numpy array, named A\n",
    "#\n",
    "A = df_model1.to_numpy()   \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.734e+03 2.755e+03 2.730e+03 ... 1.000e+00 4.000e+00 5.000e+00]\n",
      " [5.680e+02 5.760e+02 5.630e+02 ... 1.000e+00 4.000e+00 7.000e+00]\n",
      " [3.150e+03 3.210e+03 3.140e+03 ... 1.000e+00 4.000e+00 6.000e+00]\n",
      " ...\n",
      " [1.690e+03 1.690e+03 1.645e+03 ... 1.200e+01 3.000e+00 4.000e+00]\n",
      " [2.388e+03 2.396e+03 2.380e+03 ... 1.200e+01 3.000e+00 6.000e+00]\n",
      " [6.900e+02 7.110e+02 6.860e+02 ... 1.200e+01 3.000e+00 8.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's make sure it's all floating-point (here, it already is, but in other datasets it might not be)\n",
    "#\n",
    "A = A.astype('float64')  \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n",
      "y_all (just the labels/species)   are \n",
      " [5. 7. 6. ... 4. 6. 8.]\n",
      "X_all (just the features, first few rows) are \n",
      " [[2.7340e+03 2.7550e+03 2.7300e+03 2.7420e+03 3.1400e+04 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [5.6800e+02 5.7600e+02 5.6300e+02 5.7100e+02 2.7985e+06 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [3.1500e+03 3.2100e+03 3.1400e+03 3.2100e+03 2.7080e+05 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [1.5100e+03 1.5500e+03 1.5100e+03 1.5500e+03 1.1300e+04 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]\n",
      " [3.2700e+03 3.3500e+03 3.2700e+03 3.3300e+03 1.5080e+05 2.0170e+03\n",
      "  1.0000e+00 4.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "#\n",
    "# we could do this at the data-frame level, too!\n",
    "#\n",
    "\n",
    "X_all = A[:,0:8]  # X (features) ... is all rows except column 8\n",
    "y_all = A[:,8]    # y (labels) ... is all rows, column 8 only\n",
    "\n",
    "print(f\"y_all (just the labels/species)   are \\n {y_all}\")\n",
    "print(f\"X_all (just the features, first few rows) are \\n {X_all[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1859938 rows;  testing with 464985 rows\n",
      "\n",
      "Held-out data... (testing data: 464985)\n",
      "y_test: [2. 3. 9. ... 7. 6. 7.]\n",
      "\n",
      "X_test (few rows): [[1.980e+03 1.980e+03 1.951e+03 1.956e+03 7.100e+04 2.019e+03 6.000e+00\n",
      "  2.400e+01]\n",
      " [1.341e+03 1.378e+03 1.331e+03 1.363e+03 5.425e+05 2.018e+03 8.000e+00\n",
      "  8.000e+00]\n",
      " [2.180e+03 2.195e+03 2.148e+03 2.184e+03 4.860e+04 2.021e+03 8.000e+00\n",
      "  2.000e+01]\n",
      " [3.425e+03 3.445e+03 3.275e+03 3.295e+03 4.690e+05 2.021e+03 5.000e+00\n",
      "  1.200e+01]\n",
      " [2.337e+03 2.438e+03 2.301e+03 2.438e+03 2.803e+05 2.020e+03 3.000e+00\n",
      "  3.000e+01]]\n",
      "\n",
      "Data used for modeling... (training data: 1859938)\n",
      "y_train: [9. 9. 8. ... 1. 1. 5.]\n",
      "\n",
      "X_train (few rows): [[3.6900e+02 3.8500e+02 3.6900e+02 3.8100e+02 8.9090e+05 2.0200e+03\n",
      "  9.0000e+00 8.0000e+00]\n",
      " [2.0500e+03 2.0520e+03 1.9780e+03 1.9810e+03 1.2150e+05 2.0180e+03\n",
      "  1.0000e+00 3.0000e+01]\n",
      " [8.5700e+02 8.5700e+02 8.4600e+02 8.5000e+02 1.4980e+05 2.0170e+03\n",
      "  8.0000e+00 3.0000e+00]\n",
      " [4.6100e+02 4.6700e+02 4.6000e+02 4.6000e+02 8.6761e+06 2.0170e+03\n",
      "  9.0000e+00 1.4000e+01]\n",
      " [2.7000e+03 2.7000e+03 2.6700e+03 2.6800e+03 7.0000e+02 2.0180e+03\n",
      "  1.0000e+01 1.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\\n\")\n",
    "print(f\"X_test (few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\\n\")\n",
    "print(f\"X_train (few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks_cleaned_test.csv : file read into a pandas dataframe.\n",
      "[[2.982e+03 2.982e+03 2.965e+03 ... 1.200e+01 6.000e+00 4.000e+00]\n",
      " [5.920e+02 5.990e+02 5.880e+02 ... 1.200e+01 6.000e+00 3.000e+00]\n",
      " [2.368e+03 2.388e+03 2.360e+03 ... 1.200e+01 6.000e+00 3.000e+00]\n",
      " ...\n",
      " [1.600e+03 1.622e+03 1.600e+03 ... 2.000e+00 2.800e+01 6.000e+00]\n",
      " [2.568e+03 2.568e+03 2.540e+03 ... 2.000e+00 2.800e+01 4.000e+00]\n",
      " [7.310e+02 7.370e+02 7.260e+02 ... 2.000e+00 2.800e+01 0.000e+00]]\n",
      "[[2.982e+03 2.982e+03 2.965e+03 ... 1.200e+01 6.000e+00 4.000e+00]\n",
      " [5.920e+02 5.990e+02 5.880e+02 ... 1.200e+01 6.000e+00 3.000e+00]\n",
      " [2.368e+03 2.388e+03 2.360e+03 ... 1.200e+01 6.000e+00 3.000e+00]\n",
      " ...\n",
      " [1.600e+03 1.622e+03 1.600e+03 ... 2.000e+00 2.800e+01 6.000e+00]\n",
      " [2.568e+03 2.568e+03 2.540e+03 ... 2.000e+00 2.800e+01 4.000e+00]\n",
      " [7.310e+02 7.370e+02 7.260e+02 ... 2.000e+00 2.800e+01 0.000e+00]]\n",
      "\n",
      "The dataset has 111716 rows and 9 cols\n",
      "+++ Start of data definitions +++\n",
      "\n",
      "y_all (just the labels/species)   are \n",
      " [4. 3. 3. ... 6. 4. 0.]\n",
      "X_all (just the features, first few rows) are \n",
      " [[2.9820e+03 2.9820e+03 2.9650e+03 2.9710e+03 8.9000e+03 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [5.9200e+02 5.9900e+02 5.8800e+02 5.8900e+02 1.3608e+06 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [2.3680e+03 2.3880e+03 2.3600e+03 2.3770e+03 1.2590e+05 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [1.2300e+03 1.2390e+03 1.2240e+03 1.2240e+03 8.1100e+04 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]\n",
      " [1.3390e+03 1.3720e+03 1.3390e+03 1.3510e+03 6.2000e+03 2.0210e+03\n",
      "  1.2000e+01 6.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Also read the extra testing data\n",
    "\n",
    "filename_test = 'stocks_cleaned_test.csv'\n",
    "df_tidy_test = pd.read_csv(filename_test)      # encoding = \"utf-8\", \"latin1\"\n",
    "print(f\"{filename_test} : file read into a pandas dataframe.\")\n",
    "\n",
    "#\n",
    "# All of the columns need to be numeric, we'll drop Target and twoclass\n",
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1_test = df_tidy_test.drop(['Target', 'twoclass'], axis=COLUMN )\n",
    "df_model1_test.head()\n",
    "\n",
    "#\n",
    "# let's convert our dataframe to a numpy array, named B\n",
    "#\n",
    "B = df_model1_test.to_numpy()   \n",
    "print(B)\n",
    "\n",
    "#\n",
    "# let's make sure it's all floating-point (here, it already is, but in other datasets it might not be)\n",
    "#\n",
    "B = B.astype('float64')  \n",
    "print(B)\n",
    "\n",
    "#\n",
    "# nice to have NUM_ROWS and NUM_COLS around\n",
    "#\n",
    "NUM_ROWS, NUM_COLS = B.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")\n",
    "\n",
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "#\n",
    "# we could do this at the data-frame level, too!\n",
    "#\n",
    "\n",
    "X_all_test = B[:,0:8]  # X (features) ... is all rows except column 8\n",
    "y_all_test = B[:,8]    # y (labels) ... is all rows, column 8 only\n",
    "\n",
    "print(f\"y_all (just the labels/species)   are \\n {y_all_test}\")\n",
    "print(f\"X_all (just the features, first few rows) are \\n {X_all_test[0:5]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11140293 0.11211114 0.11199316 0.11208456 0.11164996]\n",
      "k:  1  cv accuracy:  0.1118\n",
      "[0.11117712 0.1125789  0.1119152  0.11176197 0.11181664]\n",
      "k:  2  cv accuracy:  0.1118\n",
      "[0.11030882 0.11051701 0.11036407 0.10934253 0.11000742]\n",
      "k:  3  cv accuracy:  0.1101\n",
      "[0.11059915 0.11067024 0.11113292 0.11064903 0.11031926]\n",
      "k:  4  cv accuracy:  0.1107\n",
      "[0.11325512 0.11334774 0.11341525 0.1124663  0.11246183]\n",
      "k:  5  cv accuracy:  0.1130\n",
      "[0.11545141 0.11578062 0.11604169 0.11539382 0.11493236]\n",
      "k:  6  cv accuracy:  0.1155\n",
      "[0.11664498 0.11722152 0.11733206 0.11692075 0.11598886]\n",
      "k:  7  cv accuracy:  0.1168\n",
      "[0.11757242 0.11852533 0.11756594 0.11749335 0.11687868]\n",
      "k:  8  cv accuracy:  0.1176\n",
      "[0.11838695 0.11851995 0.11774336 0.11745034 0.11791367]\n",
      "k:  9  cv accuracy:  0.1180\n",
      "[0.11873105 0.11928342 0.11838048 0.11788046 0.11802389]\n",
      "k: 10  cv accuracy:  0.1185\n",
      "[0.11900525 0.11904147 0.11905255 0.11866275 0.11905351]\n",
      "k: 11  cv accuracy:  0.1190\n",
      "[0.11996226 0.11997968 0.11997731 0.11984021 0.1195132 ]\n",
      "k: 12  cv accuracy:  0.1199\n",
      "[0.12071227 0.120477   0.12051765 0.12056335 0.12007237]\n",
      "k: 13  cv accuracy:  0.1205\n",
      "[0.12124454 0.12126198 0.12124617 0.12121391 0.12067455]\n",
      "k: 14  cv accuracy:  0.1211\n",
      "[0.12114508 0.1216921  0.12194243 0.121722   0.12115037]\n",
      "k: 15  cv accuracy:  0.1215\n",
      "[0.12175262 0.12231577 0.12244783 0.12220588 0.12176599]\n",
      "k: 16  cv accuracy:  0.1221\n",
      "[0.12238704 0.12292063 0.1228215  0.12274623 0.12245957]\n",
      "k: 17  cv accuracy:  0.1227\n",
      "[0.12302415 0.12313032 0.12339141 0.12339679 0.12273377]\n",
      "k: 18  cv accuracy:  0.1231\n",
      "[0.12345158 0.12347441 0.12367368 0.12375164 0.12319078]\n",
      "k: 19  cv accuracy:  0.1235\n",
      "best_k = 19   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# to do this, we use \"cross validation\"\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 84  # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,20):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "# assign best value of k to best_k\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_k = k      # at the moment this is incorrect   \n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a 'final' knn classifier, with a (best) k of 19\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned knn to use the \"best\" value of k...\n",
    "#\n",
    "# And, we should now use ALL available data to train our final predictive model:\n",
    "#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors=19)   # here, we use the best_k\n",
    "knn_model_final.fit(X_all, y_all)                              # here we use ALL the data!\n",
    "print(f\"Created + trained a 'final' knn classifier, with a (best) k of {19}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4. 1. 9. ... 4. 6. 4.]\n",
      "Actual labels: [4. 3. 3. ... 6. 4. 0.]\n",
      "\n",
      "Results on test set:  13492 correct out of 111716 total, which is  0.1208.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with extra data\n",
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = knn_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.1546\n",
      "depth:  2  cv accuracy:  0.1546\n",
      "depth:  3  cv accuracy:  0.1546\n",
      "depth:  4  cv accuracy:  0.1585\n",
      "depth:  5  cv accuracy:  0.1668\n",
      "depth:  6  cv accuracy:  0.1705\n",
      "depth:  7  cv accuracy:  0.1751\n",
      "depth:  8  cv accuracy:  0.1794\n",
      "depth:  9  cv accuracy:  0.1826\n",
      "depth: 10  cv accuracy:  0.1872\n",
      "depth: 11  cv accuracy:  0.1946\n",
      "depth: 12  cv accuracy:  0.1993\n",
      "depth: 13  cv accuracy:  0.2050\n",
      "depth: 14  cv accuracy:  0.2093\n",
      "depth: 15  cv accuracy:  0.2121\n",
      "depth: 16  cv accuracy:  0.2123\n",
      "depth: 17  cv accuracy:  0.2119\n",
      "depth: 18  cv accuracy:  0.2103\n",
      "depth: 19  cv accuracy:  0.2077\n",
      "\n",
      "best_depth = 16 is our choice for an underfitting/overfitting balance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# To compare different tree-depths, we use cross validation\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "best_d = 1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for d in range(1,20):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   # for each depth, d\n",
    "    cv_scores = cross_val_score( cv_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "    # print(cv_scores)  # we usually don't want to see the five individual scores \n",
    "    average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_d = d\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth\n",
    "best_depth = best_d   # may have to hand-tune this, depending on what happens...\n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for an underfitting/overfitting balance.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a 'final' DT classifier with max depth = 16\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our DT to use the \"best\" depth...\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "# we should have best_depth from our cv exploration\n",
    "best_depth = 16\n",
    "dtree_model_final = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_final.fit(X_all, y_all)                              # yay!  trained!\n",
    "print(\"Created and trained a 'final' DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [7. 9. 9. ... 4. 4. 4.]\n",
      "Actual labels: [4. 3. 3. ... 6. 4. 0.]\n",
      "\n",
      "Results on test set:  12041 correct out of 111716 total, which is  0.1078.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with extra data\n",
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = dtree_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04586071 0.04827758 0.04796631 0.04621788 0.138748   0.04461912\n",
      " 0.22200167 0.40630873]\n",
      "\n",
      "Feature         Open has    4.59% of the decision-making importance.\n",
      "Feature         High has    4.83% of the decision-making importance.\n",
      "Feature          Low has    4.80% of the decision-making importance.\n",
      "Feature        Close has    4.62% of the decision-making importance.\n",
      "Feature       Volume has   13.87% of the decision-making importance.\n",
      "Feature         Year has    4.46% of the decision-making importance.\n",
      "Feature        Month has   22.20% of the decision-making importance.\n",
      "Feature          Day has   40.63% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "print(dtree_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = dtree_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {df_model1.columns[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  10 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   28.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   30.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  30 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   48.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   47.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   49.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   48.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   47.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  50 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   16.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  10 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   49.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   54.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   45.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   48.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   48.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  30 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  50 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  10 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  30 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  50 cv accuracy:  0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   30.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   30.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   30.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   31.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  10 cv accuracy:  0.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  30 cv accuracy:  0.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  50 cv accuracy:  0.1566\n",
      "\n",
      "best_depth: 4 and best_num_trees: 50 are our choices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# So, to compare different parameters, let's use cv\n",
    "#\n",
    "from sklearn import ensemble  # for random forests, an ensemble classifier\n",
    "\n",
    "best_d = 1\n",
    "best_ntrees = 10   \n",
    "best_accuracy = 0\n",
    "\n",
    "for d in range(1,5):\n",
    "    for ntrees in range(10,60,20):\n",
    "        rforest_model = ensemble.RandomForestClassifier(max_depth=d, \n",
    "                                                        n_estimators=ntrees,\n",
    "                                                        verbose=1)\n",
    "        cv_scores = cross_val_score( rforest_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "        average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "        print(f\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "        if average_cv_accuracy > best_accuracy:\n",
    "            best_d = d\n",
    "            best_ntrees = ntrees\n",
    "            best_accuracy = average_cv_accuracy\n",
    "\n",
    "\n",
    "best_depth = best_d   \n",
    "best_num_trees = best_ntrees\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"best_depth: {best_depth} and best_num_trees: {best_num_trees} are our choices.\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=4 and ntrees=50\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ok!  We have tuned our RF to use the \"best\" parameters\n",
    "#\n",
    "# Now, we use ALL available data to train our final predictive model:\n",
    "#\n",
    "from sklearn import ensemble  # for random forests, an ensemble classifier\n",
    "\n",
    "\n",
    "best_depth = 4\n",
    "best_num_trees = 50\n",
    "\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_final = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_final.fit(X_all, y_all)              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4. 4. 4. ... 4. 4. 4.]\n",
      "Actual labels: [4. 3. 3. ... 6. 4. 0.]\n",
      "\n",
      "Results on test set:  15934 correct out of 111716 total, which is  0.1426.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with extra data\n",
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = rforest_model_final.predict(X_all_test)\n",
    "actual_labels = y_all_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03443071 0.04541777 0.05099852 0.05017958 0.40259039 0.3206969\n",
      " 0.04601593 0.04967019]\n",
      "\n",
      "Feature         Open has    3.44% of the decision-making importance.\n",
      "Feature         High has    4.54% of the decision-making importance.\n",
      "Feature          Low has    5.10% of the decision-making importance.\n",
      "Feature        Close has    5.02% of the decision-making importance.\n",
      "Feature       Volume has   40.26% of the decision-making importance.\n",
      "Feature         Year has   32.07% of the decision-making importance.\n",
      "Feature        Month has    4.60% of the decision-making importance.\n",
      "Feature          Day has    4.97% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# feature importances are often even more \"important\" than predictions...\n",
    "#\n",
    "#    Random forests can provide a much \"smoother\" measure of feature importance, since\n",
    "#                   they integrate over so many individual models (each tree)\n",
    "#\n",
    "#    That is, it's much less likely that a feature will have 0% importance, \n",
    "#             unless it never varies\n",
    "#\n",
    "\n",
    "print(rforest_model_final.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = rforest_model_final.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {df_model1.columns[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[-0.62228159 -0.61949894 -0.62053342 -0.6189016   0.05002699  0.71498637\n",
      "  0.74171276 -0.902306  ] -> ?     9    \n",
      "[-0.15200495 -0.15853714 -0.16484816 -0.17120035 -0.14541927 -0.70714375\n",
      " -1.6213479   1.61890759] -> ?     9    \n",
      "[-0.48575869 -0.48898066 -0.48544214 -0.48766917 -0.13823038 -1.41820882\n",
      "  0.44633018 -1.47530909] -> ?     8    \n",
      "[-0.59654367 -0.59682416 -0.59476129 -0.59679635  2.02765657 -1.41820882\n",
      "  0.74171276 -0.2147023 ] -> ?     8    \n",
      "[ 0.02983909  0.02064898  0.03113331  0.02438913 -0.1761054  -0.70714375\n",
      "  1.03709534 -0.67310477] -> ?     4    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) # scale!\n",
    "X_test_scaled = scaler.transform(X_test) # scale!\n",
    "\n",
    "y_train_scaled = y_train  # the predicted/desired labels are not scaled\n",
    "y_test_scaled = y_test  # not using the scaler\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_train_scaled[0:5,:],y_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++  TRAINING:  begin  +++++++++++++++\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.25731746\n",
      "Iteration 2, loss = 2.24704572\n",
      "Iteration 3, loss = 2.24092065\n",
      "Iteration 4, loss = 2.23563474\n",
      "Iteration 5, loss = 2.23113552\n",
      "Iteration 6, loss = 2.22588053\n",
      "Iteration 7, loss = 2.22358513\n",
      "Iteration 8, loss = 2.22269855\n",
      "Iteration 9, loss = 2.22015837\n",
      "Iteration 10, loss = 2.21979266\n",
      "Iteration 11, loss = 2.21947905\n",
      "Iteration 12, loss = 2.21847015\n",
      "Iteration 13, loss = 2.21813813\n",
      "Iteration 14, loss = 2.21960334\n",
      "Iteration 15, loss = 2.21763524\n",
      "Iteration 16, loss = 2.21622082\n",
      "Iteration 17, loss = 2.21607233\n",
      "Iteration 18, loss = 2.21562168\n",
      "Iteration 19, loss = 2.21487446\n",
      "Iteration 20, loss = 2.21742680\n",
      "Iteration 21, loss = 2.21565625\n",
      "Iteration 22, loss = 2.21629087\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 23, loss = 2.19851806\n",
      "Iteration 24, loss = 2.19588128\n",
      "Iteration 25, loss = 2.19518733\n",
      "Iteration 26, loss = 2.19493336\n",
      "Iteration 27, loss = 2.19459267\n",
      "Iteration 28, loss = 2.19540046\n",
      "Iteration 29, loss = 2.19488516\n",
      "Iteration 30, loss = 2.19483818\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 31, loss = 2.18861566\n",
      "Iteration 32, loss = 2.18792400\n",
      "Iteration 33, loss = 2.18794554\n",
      "Iteration 34, loss = 2.18760065\n",
      "Iteration 35, loss = 2.18759012\n",
      "Iteration 36, loss = 2.18765781\n",
      "Iteration 37, loss = 2.18798104\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 38, loss = 2.18600245\n",
      "Iteration 39, loss = 2.18586794\n",
      "Iteration 40, loss = 2.18573848\n",
      "Iteration 41, loss = 2.18566177\n",
      "Iteration 42, loss = 2.18560848\n",
      "Iteration 43, loss = 2.18555512\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 44, loss = 2.18508548\n",
      "Iteration 45, loss = 2.18503224\n",
      "Iteration 46, loss = 2.18501642\n",
      "Iteration 47, loss = 2.18500755\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 48, loss = 2.18488794\n",
      "Iteration 49, loss = 2.18488058\n",
      "Iteration 50, loss = 2.18487315\n",
      "Iteration 51, loss = 2.18486876\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 52, loss = 2.18484254\n",
      "Iteration 53, loss = 2.18484129\n",
      "Iteration 54, loss = 2.18483952\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 55, loss = 2.18483487\n",
      "Iteration 56, loss = 2.18483381\n",
      "Iteration 57, loss = 2.18483362\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 58, loss = 2.18483196\n",
      "Iteration 59, loss = 2.18483193\n",
      "Iteration 60, loss = 2.18483189\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "\n",
      "++++++++++  TRAINING:   end  +++++++++++++++\n",
      "The analog prediction error (the loss) is 2.1848318943608818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#\n",
    "# Here's where you can change the number of hidden layers\n",
    "# and number of neurons!\n",
    "#\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(16,8,4),  # 8 input ->  -> 1 output\n",
    "                    max_iter=100,      # how many times to train\n",
    "                    activation=\"tanh\", # the \"activation function\" input -> output\n",
    "                    solver='sgd',      # the algorithm for optimizing weights\n",
    "                    verbose=True,      # False to \"mute\" the training\n",
    "                    shuffle=True,      # reshuffle the training epochs?\n",
    "                    random_state=None, # set for reproduceability\n",
    "                    learning_rate_init=.1,       # learning rate: % of error to backprop\n",
    "                    learning_rate = 'adaptive')  # soften feedback as it converges\n",
    "\n",
    "# documentation:\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n",
    "#     Try verbose / activation \"relu\" / other network sizes ...\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_classifier.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"\\n++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "print(f\"The analog prediction error (the loss) is {nn_classifier.loss_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 361644 out of 1859938, which is  0.1944.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# how did it do on the testing data?\n",
    "#\n",
    "\n",
    "#\n",
    "# which one do we want: classifier or regressor?\n",
    "#\n",
    "\n",
    "def ascii_table_for_classifier(Xsc,y,nn,scaler):\n",
    "    \"\"\" a table including predictions using nn.predict \"\"\"\n",
    "    predictions = nn.predict(Xsc)            # all predictions\n",
    "    prediction_probs = nn.predict_proba(Xsc) # all prediction probabilities\n",
    "    Xpr = scaler.inverse_transform(Xsc)      # Xpr is the \"X to print\": unscaled data!\n",
    "    # count correct\n",
    "    num_correct = 0\n",
    "    # printing\n",
    "    # print(f\"{'input ':>28s} -> {'pred':^6s} {'des.':^6s}\") \n",
    "    for i in range(len(y)):\n",
    "        pred = predictions[i]\n",
    "        pred_probs = prediction_probs[i,:]\n",
    "        desired = y[i]\n",
    "        if pred != desired: result = \"  incorrect: \" + str(pred_probs)\n",
    "        else: result = \"  correct\"; num_correct += 1\n",
    "        # Xpr = Xsc  # if you want to see the scaled versions\n",
    "        #print(f\"{Xpr[i,:]!s:>28s} -> {pred:^6.0f} {desired:^6.0f} {result:^10s}\") \n",
    "    print(f\"\\ncorrect predictions: {num_correct} out of {len(y)}, which is {num_correct/len(y):7.4f}.\")\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "# let's see how it did on the test data (also the training data!)\n",
    "#\n",
    "ascii_table_for_classifier(X_train_scaled,\n",
    "                           y_train_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler)   \n",
    "#\n",
    "# other things...\n",
    "#\n",
    "if False:  # do we want to see all of the parameters?\n",
    "    nn = nn_classifier  # less to type?\n",
    "    print(\"\\n\\n+++++ parameters, weights, etc. +++++\\n\")\n",
    "    print(f\"\\nweights/coefficients:\\n\")\n",
    "    for wts in nn.coefs_:\n",
    "        print(wts)\n",
    "    print(f\"\\nintercepts: {nn.intercepts_}\")\n",
    "    print(f\"\\nall parameters: {nn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[ 0.03899406  0.03549253  0.04776377  0.04137425 -0.16919196 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     5    \n",
      "[-0.56650895 -0.56654721 -0.56551035 -0.5656374   0.53716061 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     7    \n",
      "[ 0.15528642  0.16120528  0.16379625  0.17222706 -0.10808076 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     6    \n",
      "[-0.30317384 -0.29743904 -0.29750362 -0.29190898 -0.17432285 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     7    \n",
      "[ 0.1888323   0.19988612  0.20058704  0.20577906 -0.13871294 -1.41835118\n",
      " -1.62185841 -1.36060155] -> ?     5    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_all)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_all)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_all_scaled = scaler.transform(X_all) # scale!\n",
    "y_all_scaled = y_all  # the predicted/desired labels are not scaled\n",
    "\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_all_scaled[0:5,:], y_all_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++  TRAINING:  begin  +++++++++++++++\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.25603226\n",
      "Iteration 2, loss = 2.23932127\n",
      "Iteration 3, loss = 2.22949449\n",
      "Iteration 4, loss = 2.22317488\n",
      "Iteration 5, loss = 2.21951116\n",
      "Iteration 6, loss = 2.21758905\n",
      "Iteration 7, loss = 2.21606429\n",
      "Iteration 8, loss = 2.21477007\n",
      "Iteration 9, loss = 2.21372226\n",
      "Iteration 10, loss = 2.21279148\n",
      "Iteration 11, loss = 2.21171109\n",
      "Iteration 12, loss = 2.21100545\n",
      "Iteration 13, loss = 2.20985326\n",
      "Iteration 14, loss = 2.20952590\n",
      "Iteration 15, loss = 2.20900038\n",
      "Iteration 16, loss = 2.20844567\n",
      "Iteration 17, loss = 2.20841703\n",
      "Iteration 18, loss = 2.20791978\n",
      "Iteration 19, loss = 2.20747097\n",
      "Iteration 20, loss = 2.20719127\n",
      "Iteration 21, loss = 2.20740549\n",
      "Iteration 22, loss = 2.20694187\n",
      "Iteration 23, loss = 2.20731050\n",
      "Iteration 24, loss = 2.20712924\n",
      "Iteration 25, loss = 2.20639371\n",
      "Iteration 26, loss = 2.20633515\n",
      "Iteration 27, loss = 2.20647400\n",
      "Iteration 28, loss = 2.20619339\n",
      "Iteration 29, loss = 2.20620025\n",
      "Iteration 30, loss = 2.20751321\n",
      "Iteration 31, loss = 2.20670696\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 32, loss = 2.19364701\n",
      "Iteration 33, loss = 2.19304380\n",
      "Iteration 34, loss = 2.19249889\n",
      "Iteration 35, loss = 2.19234231\n",
      "Iteration 36, loss = 2.19242268\n",
      "Iteration 37, loss = 2.19234313\n",
      "Iteration 38, loss = 2.19219061\n",
      "Iteration 39, loss = 2.19214185\n",
      "Iteration 40, loss = 2.19209537\n",
      "Iteration 41, loss = 2.19282760\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 42, loss = 2.18903583\n",
      "Iteration 43, loss = 2.18826160\n",
      "Iteration 44, loss = 2.18754796\n",
      "Iteration 45, loss = 2.18691562\n",
      "Iteration 46, loss = 2.18628506\n",
      "Iteration 47, loss = 2.18614576\n",
      "Iteration 48, loss = 2.18604155\n",
      "Iteration 49, loss = 2.18594861\n",
      "Iteration 50, loss = 2.18590172\n",
      "Iteration 51, loss = 2.18593785\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 52, loss = 2.18435607\n",
      "Iteration 53, loss = 2.18426861\n",
      "Iteration 54, loss = 2.18424164\n",
      "Iteration 55, loss = 2.18421812\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 56, loss = 2.18387957\n",
      "Iteration 57, loss = 2.18384363\n",
      "Iteration 58, loss = 2.18384139\n",
      "Iteration 59, loss = 2.18382623\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 60, loss = 2.18376186\n",
      "Iteration 61, loss = 2.18375299\n",
      "Iteration 62, loss = 2.18374941\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 63, loss = 2.18373515\n",
      "Iteration 64, loss = 2.18373202\n",
      "Iteration 65, loss = 2.18373220\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 66, loss = 2.18372723\n",
      "Iteration 67, loss = 2.18372701\n",
      "Iteration 68, loss = 2.18372702\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 69, loss = 2.18372598\n",
      "Iteration 70, loss = 2.18372596\n",
      "Iteration 71, loss = 2.18372594\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "\n",
      "++++++++++  TRAINING:   end  +++++++++++++++\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nn_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-afdce37fd9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mnn_classifier_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n++++++++++  TRAINING:   end  +++++++++++++++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The analog prediction error (the loss) is {nn_classifier.loss_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#\n",
    "# Here's where you can change the number of hidden layers\n",
    "# and number of neurons!\n",
    "#\n",
    "nn_classifier_final = MLPClassifier(hidden_layer_sizes=(16,8,4),  # 8 input ->  -> 1 output\n",
    "                    max_iter=100,      # how many times to train\n",
    "                    activation=\"tanh\", # the \"activation function\" input -> output\n",
    "                    solver='sgd',      # the algorithm for optimizing weights\n",
    "                    verbose=True,      # False to \"mute\" the training\n",
    "                    shuffle=True,      # reshuffle the training epochs?\n",
    "                    random_state=None, # set for reproduceability\n",
    "                    learning_rate_init=.1,       # learning rate: % of error to backprop\n",
    "                    learning_rate = 'adaptive')  # soften feedback as it converges\n",
    "\n",
    "# documentation:\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n",
    "#     Try verbose / activation \"relu\" / other network sizes ...\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_classifier_final.fit(X_all_scaled, y_all_scaled)\n",
    "print(\"\\n++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "print(f\"The analog prediction error (the loss) is {nn_classifier_final.loss_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii_table_for_classifier(Xsc,y,nn,scaler):\n",
    "    \"\"\" a table including predictions using nn.predict \"\"\"\n",
    "    predictions = nn.predict(Xsc)            # all predictions\n",
    "    prediction_probs = nn.predict_proba(Xsc) # all prediction probabilities\n",
    "    Xpr = scaler.inverse_transform(Xsc)      # Xpr is the \"X to print\": unscaled data!\n",
    "    # count correct\n",
    "    num_correct = 0\n",
    "    # printing\n",
    "    # print(f\"{'input ':>28s} -> {'pred':^6s} {'des.':^6s}\") \n",
    "    for i in range(len(y)):\n",
    "        pred = predictions[i]\n",
    "        pred_probs = prediction_probs[i,:]\n",
    "        desired = y[i]\n",
    "        if pred != desired: result = \"  incorrect: \" + str(pred_probs)\n",
    "        else: result = \"  correct\"; num_correct += 1\n",
    "        # Xpr = Xsc  # if you want to see the scaled versions\n",
    "        #print(f\"{Xpr[i,:]!s:>28s} -> {pred:^6.0f} {desired:^6.0f} {result:^10s}\") \n",
    "    print(f\"\\ncorrect predictions: {num_correct} out of {len(y)}, which is {num_correct/len(y):7.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[ 0.10873142  0.09862812  0.11468033  0.10581479 -0.1740224   1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     4    \n",
      "[-0.5598951  -0.56032328 -0.55851038 -0.56070044  0.16939298  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     3    \n",
      "[-0.06304125 -0.06562582 -0.05666186 -0.0603943  -0.14430156  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     3    \n",
      "[-0.38140819 -0.38334934 -0.37838867 -0.38301901 -0.15568185  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     1    \n",
      "[-0.35091434 -0.34657195 -0.3458195  -0.34748272 -0.17470827  1.42605144\n",
      "  1.62786051 -1.13150724] -> ?     5    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_all_test_scaled = scaler.transform(X_all_test) # scale!\n",
    "\n",
    "y_all_test_scaled = y_all_test  # the predicted/desired labels are not scaled\n",
    "\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_all_test_scaled[0:5,:], y_all_test_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 18710 out of 111716, which is  0.1675.\n"
     ]
    }
   ],
   "source": [
    "# Test with extra Data\n",
    "#\n",
    "# let's see how it did on the extra test data \n",
    "#\n",
    "ascii_table_for_classifier(X_all_test_scaled,\n",
    "                           y_all_test_scaled,\n",
    "                           nn_classifier_final,\n",
    "                           scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Classes\n",
    "|          |   KNN   | Decision Tree | Random Forest| Neural Network |\n",
    "| -------- | ------- |  -----------  |  ----------- |  -----------   |\n",
    "| Training | 51.07 % |    66.96 %    |    53.46 %   |     58.45 %    |\n",
    "| Test     | 51.87 % |    47.15 %    |    47.15 %   |     50.87 %    |\n",
    "\n",
    "\n",
    "### Ten Classes\n",
    "|          |   KNN   | Decision Tree | Random Forest| Neural Network |\n",
    "| -------- | ------- |  -----------  |  ----------- |  -----------   |\n",
    "| Training | 12.35 % |    20.23 %    |    15.66 %   |     19.44 %    |\n",
    "| Test     | 12.08 % |    10.78 %    |    14.26 %   |     16.75 %    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2022 Data into training data (Ten classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data \n",
    "# Jan 2017 - Feb 2022\n",
    "\n",
    "X_together = np.concatenate((X_all, X_all_test))\n",
    "y_together = np.concatenate((y_all, y_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 1949311 rows;  testing with 487328 rows\n",
      "\n",
      "Held-out data... (testing data: 487328)\n",
      "y_test: [5. 0. 6. ... 3. 4. 7.]\n",
      "\n",
      "X_test (few rows): [[1.7610e+03 1.7750e+03 1.7600e+03 1.7680e+03 1.0297e+06 2.0170e+03\n",
      "  3.0000e+00 1.6000e+01]\n",
      " [4.8300e+02 4.8900e+02 4.8100e+02 4.8600e+02 2.7007e+06 2.0180e+03\n",
      "  7.0000e+00 3.0000e+01]\n",
      " [5.4010e+03 5.4260e+03 5.3290e+03 5.3910e+03 1.2346e+06 2.0190e+03\n",
      "  9.0000e+00 2.7000e+01]\n",
      " [9.1600e+02 9.2100e+02 9.0900e+02 9.1400e+02 1.7810e+05 2.0170e+03\n",
      "  5.0000e+00 1.8000e+01]\n",
      " [2.5950e+03 2.6340e+03 2.5860e+03 2.5960e+03 1.0650e+05 2.0210e+03\n",
      "  6.0000e+00 1.4000e+01]]\n",
      "\n",
      "Data used for modeling... (training data: 1949311)\n",
      "y_train: [6. 3. 0. ... 0. 1. 5.]\n",
      "\n",
      "X_train (few rows): [[1.3940e+03 1.3970e+03 1.3850e+03 1.3860e+03 2.6000e+03 2.0170e+03\n",
      "  6.0000e+00 2.2000e+01]\n",
      " [1.8160e+03 1.8550e+03 1.7780e+03 1.8330e+03 1.9140e+05 2.0190e+03\n",
      "  3.0000e+00 1.0000e+00]\n",
      " [2.9380e+03 3.0150e+03 2.9350e+03 2.9800e+03 4.9338e+06 2.0180e+03\n",
      "  1.0000e+01 1.1000e+01]\n",
      " [2.0100e+03 2.0100e+03 1.9950e+03 2.0000e+03 3.8400e+04 2.0190e+03\n",
      "  1.2000e+01 1.9000e+01]\n",
      " [5.8300e+03 5.9300e+03 5.8200e+03 5.8800e+03 3.5710e+05 2.0210e+03\n",
      "  1.0000e+00 1.8000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_together, y_together, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\\n\")\n",
    "print(f\"X_test (few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\\n\")\n",
    "print(f\"X_train (few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11206899 0.11167769 0.11145482 0.11174781 0.11143003]\n",
      "k:  1  cv accuracy:  0.1117\n",
      "[0.11245117 0.11233946 0.11138044 0.11213256 0.11134025]\n",
      "k:  2  cv accuracy:  0.1119\n",
      "[0.11066082 0.11113648 0.10990812 0.11051147 0.1097525 ]\n",
      "k:  3  cv accuracy:  0.1104\n",
      "[0.11070442 0.11182646 0.11053142 0.11067819 0.10990384]\n",
      "k:  4  cv accuracy:  0.1107\n",
      "[0.11413123 0.11368865 0.11279889 0.11288668 0.11219697]\n",
      "k:  5  cv accuracy:  0.1131\n",
      "[0.11618065 0.11557137 0.11506379 0.11546966 0.11486973]\n",
      "k:  6  cv accuracy:  0.1154\n",
      "[0.1177145  0.1170052  0.11647711 0.11680347 0.11676786]\n",
      "k:  7  cv accuracy:  0.1170\n",
      "[0.11815568 0.11743869 0.11664897 0.11731134 0.11699358]\n",
      "k:  8  cv accuracy:  0.1173\n",
      "[0.11833266 0.11726683 0.11721584 0.11732673 0.11719365]\n",
      "k:  9  cv accuracy:  0.1175\n",
      "[0.11885335 0.11797734 0.11761598 0.11762171 0.11732447]\n",
      "k: 10  cv accuracy:  0.1179\n",
      "[0.11927914 0.11826206 0.11842652 0.11798851 0.11808628]\n",
      "k: 11  cv accuracy:  0.1184\n",
      "[0.12015893 0.11924445 0.1190216  0.11914533 0.11901995]\n",
      "k: 12  cv accuracy:  0.1193\n",
      "[0.12077452 0.11999856 0.12004761 0.11978403 0.12019987]\n",
      "k: 13  cv accuracy:  0.1202\n",
      "[0.12194928 0.12089375 0.12017073 0.12068691 0.12059488]\n",
      "k: 14  cv accuracy:  0.1209\n",
      "[0.12190055 0.12121181 0.12040927 0.12104858 0.1208873 ]\n",
      "k: 15  cv accuracy:  0.1211\n",
      "[0.12228016 0.12146575 0.12106079 0.1217001  0.12162602]\n",
      "k: 16  cv accuracy:  0.1216\n",
      "[0.1225777  0.12172994 0.12158918 0.1223157  0.12202617]\n",
      "k: 17  cv accuracy:  0.1220\n",
      "[0.12323177 0.12180946 0.12235612 0.12277228 0.12199282]\n",
      "k: 18  cv accuracy:  0.1224\n",
      "[0.12329846 0.12219934 0.12274856 0.12334428 0.12214159]\n",
      "k: 19  cv accuracy:  0.1227\n",
      "best_k = 19   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# to do this, we use \"cross validation\"\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 84  # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,20):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "# assign best value of k to best_k\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_k = k      # at the moment this is incorrect   \n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a knn classifier, now tuned with a (best) k of 19\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# With the best k, we build and train a new model:\n",
    "#\n",
    "# Now, we use best_k instead of the original, randomly-guessed value    \n",
    "#\n",
    "best_k = 19\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_tuned = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k!\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Created + trained a knn classifier, now tuned with a (best) k of {best_k}\")  \n",
    "\n",
    "# How does it do?!  The next cell will show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4. 9. 4. ... 6. 3. 5.]\n",
      "Actual labels: [5. 0. 6. ... 3. 4. 7.]\n",
      "\n",
      "Results on test set:  60573 correct out of 487328 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Re-create and re-run the  \"Model-testing Cell\"     How does it do with best_k?!\n",
    "#\n",
    "predicted_labels = knn_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# And, the overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on test set:  1834 correct out of 14774 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Predictions on data in 2022\n",
    "#\n",
    "\n",
    "predicted_labels = predicted_labels = knn_model_tuned.predict(X_test)\n",
    "correct_2022 = 0\n",
    "total_2022 = 0\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][5] == 2022:\n",
    "        if y_test[i] == predicted_labels[i]:\n",
    "            correct_2022 += 1\n",
    "        total_2022 += 1\n",
    "\n",
    "print(f\"\\nResults on test set:  {correct_2022} correct out of {total_2022} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1  cv accuracy:  0.1539\n",
      "depth:  2  cv accuracy:  0.1539\n",
      "depth:  3  cv accuracy:  0.1539\n",
      "depth:  4  cv accuracy:  0.1563\n",
      "depth:  5  cv accuracy:  0.1625\n",
      "depth:  6  cv accuracy:  0.1667\n",
      "depth:  7  cv accuracy:  0.1708\n",
      "depth:  8  cv accuracy:  0.1766\n",
      "depth:  9  cv accuracy:  0.1806\n",
      "depth: 10  cv accuracy:  0.1858\n",
      "depth: 11  cv accuracy:  0.1917\n",
      "depth: 12  cv accuracy:  0.1979\n",
      "depth: 13  cv accuracy:  0.2042\n",
      "depth: 14  cv accuracy:  0.2086\n",
      "depth: 15  cv accuracy:  0.2114\n",
      "depth: 16  cv accuracy:  0.2122\n",
      "depth: 17  cv accuracy:  0.2116\n",
      "depth: 18  cv accuracy:  0.2099\n",
      "depth: 19  cv accuracy:  0.2071\n",
      "\n",
      "best_depth = 16 is our choice for an underfitting/overfitting balance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# To compare different tree-depths, we use cross validation\n",
    "#\n",
    "from sklearn import tree      # for decision trees\n",
    "\n",
    "best_d = 1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for d in range(1,20):\n",
    "    cv_model = tree.DecisionTreeClassifier(max_depth=d)   # for each depth, d\n",
    "    cv_scores = cross_val_score( cv_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "    # print(cv_scores)  # we usually don't want to see the five individual scores \n",
    "    average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "    print(f\"depth: {d:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "    \n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_accuracy = average_cv_accuracy\n",
    "        best_d = d\n",
    "\n",
    "    \n",
    "    \n",
    "# assign best value of d to best_depth\n",
    "best_depth = best_d   # may have to hand-tune this, depending on what happens...\n",
    "print()\n",
    "print(f\"best_depth = {best_depth} is our choice for an underfitting/overfitting balance.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a DT classifier with max depth = 16\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# this time, with the best depth, best_d, found by cross-validation model tuning:\n",
    "#\n",
    "best_depth = 16\n",
    "# we should have best_depth from our cv exploration\n",
    "dtree_model_tuned = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "dtree_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a DT classifier with max depth =\", best_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4. 9. 8. ... 9. 4. 6.]\n",
      "Actual  labels  : [5. 0. 6. ... 3. 4. 7.]\n",
      "\n",
      "Results on test set:  102964 correct out of 487328 total, which is  0.2113.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This cell will \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well our model does on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set:\n",
    "\n",
    "# the function knn_model.predict is the instantiation of our model\n",
    "# it's what runs the k-nearest-neighbors algorithm:\n",
    "predicted_labels = dtree_model_tuned.predict(X_test)   \n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total, which is {num_correct/total:7.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on test set:  3450 correct out of 14774 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Predictions on data in 2022\n",
    "#\n",
    "\n",
    "predicted_labels = predicted_labels = dtree_model_tuned.predict(X_test)\n",
    "correct_2022 = 0\n",
    "total_2022 = 0\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][5] == 2022:\n",
    "        if y_test[i] == predicted_labels[i]:\n",
    "            correct_2022 += 1\n",
    "        total_2022 += 1\n",
    "\n",
    "print(f\"\\nResults on test set:  {correct_2022} correct out of {total_2022} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04993694 0.05450757 0.05258089 0.05129034 0.14691065 0.05825783\n",
      " 0.22482789 0.36168789]\n",
      "\n",
      "Feature         Open has    4.99% of the decision-making importance.\n",
      "Feature         High has    5.45% of the decision-making importance.\n",
      "Feature          Low has    5.26% of the decision-making importance.\n",
      "Feature        Close has    5.13% of the decision-making importance.\n",
      "Feature       Volume has   14.69% of the decision-making importance.\n",
      "Feature         Year has    5.83% of the decision-making importance.\n",
      "Feature        Month has   22.48% of the decision-making importance.\n",
      "Feature          Day has   36.17% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "print(dtree_model_tuned.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = dtree_model_tuned.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  10 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   28.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   26.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   25.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   23.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  30 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   35.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   35.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  1 ntrees:  50 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  10 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   38.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   39.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   39.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   39.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   38.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  30 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  2 ntrees:  50 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  10 cv accuracy:  0.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   53.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   55.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   56.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   54.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   55.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  30 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  3 ntrees:  50 cv accuracy:  0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   24.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  10 cv accuracy:  0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  30 cv accuracy:  0.1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  4 ntrees:  50 cv accuracy:  0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   28.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   28.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   28.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   28.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   29.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  10 cv accuracy:  0.1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  30 cv accuracy:  0.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  5 ntrees:  50 cv accuracy:  0.1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   33.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   35.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   35.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  6 ntrees:  10 cv accuracy:  0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  6 ntrees:  30 cv accuracy:  0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  6 ntrees:  50 cv accuracy:  0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   42.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  7 ntrees:  10 cv accuracy:  0.1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  7 ntrees:  30 cv accuracy:  0.1644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-adf52ce33a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                         \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntrees\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                         verbose=1)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrforest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 5 means 80/20 split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0maverage_cv_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# more likely, only their average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# So, to compare different parameters, let's use cv\n",
    "#\n",
    "from sklearn import ensemble  # for random forests, an ensemble classifier\n",
    "\n",
    "best_d = 1\n",
    "best_ntrees = 10   \n",
    "best_accuracy = 0\n",
    "\n",
    "for d in range(1,10):\n",
    "    for ntrees in range(10,60,20):\n",
    "        rforest_model = ensemble.RandomForestClassifier(max_depth=d, \n",
    "                                                        n_estimators=ntrees,\n",
    "                                                        verbose=1)\n",
    "        cv_scores = cross_val_score( rforest_model, X_train, y_train, cv=5 ) # 5 means 80/20 split\n",
    "        average_cv_accuracy = cv_scores.mean()  # more likely, only their average\n",
    "        print(f\"depth: {d:2d} ntrees: {ntrees:3d} cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "        if average_cv_accuracy > best_accuracy:\n",
    "            best_d = d\n",
    "            best_ntrees = ntrees\n",
    "            best_accuracy = average_cv_accuracy\n",
    "\n",
    "\n",
    "best_depth = best_d   \n",
    "best_num_trees = best_ntrees\n",
    "\n",
    "\n",
    "print()\n",
    "print(f\"best_depth: {best_depth} and best_num_trees: {best_num_trees} are our choices.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built an RF classifier with depth=7 and ntrees=10\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "\n",
    "best_depth = 7\n",
    "best_num_trees = 10\n",
    "# we should have best_depth and best_num_trees\n",
    "rforest_model_tuned = ensemble.RandomForestClassifier(max_depth=best_depth, \n",
    "                                                      n_estimators=best_num_trees)\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "rforest_model_tuned.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(f\"Built an RF classifier with depth={best_depth} and ntrees={best_num_trees}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4. 4. 4. ... 9. 4. 4.]\n",
      "Actual  labels  : [5. 0. 6. ... 3. 4. 7.]\n",
      "\n",
      "Results on test set:  81443 correct out of 487328 total.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is our \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set!\n",
    "predicted_labels = rforest_model_tuned.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on test set:  2414 correct out of 14774 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Predictions on data in 2022\n",
    "#\n",
    "\n",
    "predicted_labels = rforest_model_tuned.predict(X_test)\n",
    "correct_2022 = 0\n",
    "total_2022 = 0\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][5] == 2022:\n",
    "        if y_test[i] == predicted_labels[i]:\n",
    "            correct_2022 += 1\n",
    "        total_2022 += 1\n",
    "\n",
    "print(f\"\\nResults on test set:  {correct_2022} correct out of {total_2022} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02704365 0.03163143 0.05063644 0.04105016 0.36604529 0.30715154\n",
      " 0.07965982 0.09678167]\n",
      "\n",
      "Feature         Open has    2.70% of the decision-making importance.\n",
      "Feature         High has    3.16% of the decision-making importance.\n",
      "Feature          Low has    5.06% of the decision-making importance.\n",
      "Feature        Close has    4.11% of the decision-making importance.\n",
      "Feature       Volume has   36.60% of the decision-making importance.\n",
      "Feature         Year has   30.72% of the decision-making importance.\n",
      "Feature        Month has    7.97% of the decision-making importance.\n",
      "Feature          Day has    9.68% of the decision-making importance.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# feature importances are often even more \"important\" than predictions...\n",
    "#\n",
    "#    Random forests can provide a much \"smoother\" measure of feature importance, since\n",
    "#                   they integrate over so many individual models (each tree)\n",
    "#\n",
    "#    That is, it's much less likely that a feature will have 0% importance, \n",
    "#             unless it never varies\n",
    "#\n",
    "\n",
    "print(rforest_model_tuned.feature_importances_)\n",
    "print()\n",
    "\n",
    "# let's see them with each feature name:\n",
    "IMPs = rforest_model_tuned.feature_importances_\n",
    "\n",
    "# enumerate is great when you want indices _and_ elements!\n",
    "for i, importance in enumerate(IMPs):\n",
    "    perc = importance*100\n",
    "    print(f\"Feature {COLUMNS[i]:>12s} has {perc:>7.2f}% of the decision-making importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    input  -> pred  des. \n",
      "[-0.33353667 -0.33759165 -0.33084057 -0.33566615 -0.17773678 -1.42468379\n",
      " -0.12196947  0.7022332 ] -> ?     6    \n",
      "[-0.21692752 -0.21250959 -0.22088545 -0.21210996 -0.12889012 -0.07870281\n",
      " -0.98203158 -1.71050173] -> ?     3    \n",
      "[ 0.09310911  0.10429214  0.10282464  0.10493468  1.09807162 -0.7516933\n",
      "  1.02478001 -0.56158033] -> ?     0    \n",
      "[-0.16332048 -0.17017832 -0.16017232 -0.16594914 -0.16847454 -0.07870281\n",
      "  1.59815476  0.35755678] -> ?     4    \n",
      "[ 0.89224096  0.90039304  0.9100015   0.90652968 -0.08601994  1.26727816\n",
      " -1.55540633  0.24266464] -> ?     2    \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) # scale!\n",
    "X_test_scaled = scaler.transform(X_test) # scale!\n",
    "\n",
    "y_train_scaled = y_train  # the predicted/desired labels are not scaled\n",
    "y_test_scaled = y_test  # not using the scaler\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>58s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        print(f\"{X[i,:]!s:>58s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_train_scaled[0:5,:],y_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++++++++++  TRAINING:  begin  +++++++++++++++\n",
      "\n",
      "\n",
      "Iteration 1, loss = 2.25806829\n",
      "Iteration 2, loss = 2.24424242\n",
      "Iteration 3, loss = 2.23463387\n",
      "Iteration 4, loss = 2.22816392\n",
      "Iteration 5, loss = 2.22408751\n",
      "Iteration 6, loss = 2.22111155\n",
      "Iteration 7, loss = 2.21915945\n",
      "Iteration 8, loss = 2.21800190\n",
      "Iteration 9, loss = 2.21666596\n",
      "Iteration 10, loss = 2.21611800\n",
      "Iteration 11, loss = 2.21587675\n",
      "Iteration 12, loss = 2.21496308\n",
      "Iteration 13, loss = 2.21428994\n",
      "Iteration 14, loss = 2.21376214\n",
      "Iteration 15, loss = 2.21473252\n",
      "Iteration 16, loss = 2.21389073\n",
      "Iteration 17, loss = 2.21323910\n",
      "Iteration 18, loss = 2.21373462\n",
      "Iteration 19, loss = 2.21329928\n",
      "Iteration 20, loss = 2.21259369\n",
      "Iteration 21, loss = 2.21199246\n",
      "Iteration 22, loss = 2.21406178\n",
      "Iteration 23, loss = 2.21207935\n",
      "Iteration 24, loss = 2.21187909\n",
      "Iteration 25, loss = 2.21138981\n",
      "Iteration 26, loss = 2.21194595\n",
      "Iteration 27, loss = 2.21163981\n",
      "Iteration 28, loss = 2.21046230\n",
      "Iteration 29, loss = 2.21273963\n",
      "Iteration 30, loss = 2.21327557\n",
      "Iteration 31, loss = 2.21168382\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 32, loss = 2.19862557\n",
      "Iteration 33, loss = 2.19810197\n",
      "Iteration 34, loss = 2.19778357\n",
      "Iteration 35, loss = 2.19787430\n",
      "Iteration 36, loss = 2.19759253\n",
      "Iteration 37, loss = 2.19774665\n",
      "Iteration 38, loss = 2.19734664\n",
      "Iteration 39, loss = 2.19725967\n",
      "Iteration 40, loss = 2.19729417\n",
      "Iteration 41, loss = 2.19734565\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 42, loss = 2.19344146\n",
      "Iteration 43, loss = 2.19316633\n",
      "Iteration 44, loss = 2.19310501\n",
      "Iteration 45, loss = 2.19307401\n",
      "Iteration 46, loss = 2.19298240\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 47, loss = 2.19195531\n",
      "Iteration 48, loss = 2.19190392\n",
      "Iteration 49, loss = 2.19186677\n",
      "Iteration 50, loss = 2.19185163\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 51, loss = 2.19162560\n",
      "Iteration 52, loss = 2.19160159\n",
      "Iteration 53, loss = 2.19158958\n",
      "Iteration 54, loss = 2.19158514\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 55, loss = 2.19154021\n",
      "Iteration 56, loss = 2.19153181\n",
      "Iteration 57, loss = 2.19152952\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 58, loss = 2.19152293\n",
      "Iteration 59, loss = 2.19151822\n",
      "Iteration 60, loss = 2.19151787\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 61, loss = 2.19151452\n",
      "Iteration 62, loss = 2.19151445\n",
      "Iteration 63, loss = 2.19151440\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 64, loss = 2.19151368\n",
      "Iteration 65, loss = 2.19151367\n",
      "Iteration 66, loss = 2.19151366\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "\n",
      "++++++++++  TRAINING:   end  +++++++++++++++\n",
      "The analog prediction error (the loss) is 2.1915136574097795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#\n",
    "# Here's where you can change the number of hidden layers\n",
    "# and number of neurons!\n",
    "#\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(16,8,4),  # 8 input ->  -> 1 output\n",
    "                    max_iter=100,      # how many times to train\n",
    "                    activation=\"tanh\", # the \"activation function\" input -> output\n",
    "                    solver='sgd',      # the algorithm for optimizing weights\n",
    "                    verbose=True,      # False to \"mute\" the training\n",
    "                    shuffle=True,      # reshuffle the training epochs?\n",
    "                    random_state=None, # set for reproduceability\n",
    "                    learning_rate_init=.1,       # learning rate: % of error to backprop\n",
    "                    learning_rate = 'adaptive')  # soften feedback as it converges\n",
    "\n",
    "# documentation:\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html \n",
    "#     Try verbose / activation \"relu\" / other network sizes ...\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_classifier.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"\\n++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "print(f\"The analog prediction error (the loss) is {nn_classifier.loss_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 377789 out of 1949311, which is  0.1938.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# how did it do on the training data?\n",
    "#\n",
    "\n",
    "#\n",
    "# which one do we want: classifier or regressor?\n",
    "#\n",
    "\n",
    "def ascii_table_for_classifier(Xsc,y,nn,scaler):\n",
    "    \"\"\" a table including predictions using nn.predict \"\"\"\n",
    "    predictions = nn.predict(Xsc)            # all predictions\n",
    "    prediction_probs = nn.predict_proba(Xsc) # all prediction probabilities\n",
    "    Xpr = scaler.inverse_transform(Xsc)      # Xpr is the \"X to print\": unscaled data!\n",
    "    # count correct\n",
    "    num_correct = 0\n",
    "    # printing\n",
    "    # print(f\"{'input ':>28s} -> {'pred':^6s} {'des.':^6s}\") \n",
    "    for i in range(len(y)):\n",
    "        pred = predictions[i]\n",
    "        pred_probs = prediction_probs[i,:]\n",
    "        desired = y[i]\n",
    "        if pred != desired: result = \"  incorrect: \" + str(pred_probs)\n",
    "        else: result = \"  correct\"; num_correct += 1\n",
    "        # Xpr = Xsc  # if you want to see the scaled versions\n",
    "        #print(f\"{Xpr[i,:]!s:>28s} -> {pred:^6.0f} {desired:^6.0f} {result:^10s}\") \n",
    "    print(f\"\\ncorrect predictions: {num_correct} out of {len(y)}, which is {num_correct/len(y):7.4f}.\")\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "# let's see how it did on the test data (also the training data!)\n",
    "#\n",
    "ascii_table_for_classifier(X_train_scaled,\n",
    "                           y_train_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler)   \n",
    "#\n",
    "# other things...\n",
    "#\n",
    "if False:  # do we want to see all of the parameters?\n",
    "    nn = nn_classifier  # less to type?\n",
    "    print(\"\\n\\n+++++ parameters, weights, etc. +++++\\n\")\n",
    "    print(f\"\\nweights/coefficients:\\n\")\n",
    "    for wts in nn.coefs_:\n",
    "        print(wts)\n",
    "    print(f\"\\nintercepts: {nn.intercepts_}\")\n",
    "    print(f\"\\nall parameters: {nn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct predictions: 93860 out of 487328, which is  0.1926.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's see how it did on the testing data \n",
    "#\n",
    "ascii_table_for_classifier(X_test_scaled,\n",
    "                           y_test_scaled,\n",
    "                           nn_classifier,\n",
    "                           scaler)   \n",
    "#\n",
    "# other things...\n",
    "#\n",
    "if False:  # do we want to see all of the parameters?\n",
    "    nn = nn_classifier  # less to type?\n",
    "    print(\"\\n\\n+++++ parameters, weights, etc. +++++\\n\")\n",
    "    print(f\"\\nweights/coefficients:\\n\")\n",
    "    for wts in nn.coefs_:\n",
    "        print(wts)\n",
    "    print(f\"\\nintercepts: {nn.intercepts_}\")\n",
    "    print(f\"\\nall parameters: {nn.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on test set:  2652 correct out of 14774 total.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Predictions on data in 2022\n",
    "#\n",
    "\n",
    "predicted_labels = nn_classifier.predict(X_test_scaled)\n",
    "correct_2022 = 0\n",
    "total_2022 = 0\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i][5] == 2022:\n",
    "        if y_test[i] == predicted_labels[i]:\n",
    "            correct_2022 += 1\n",
    "        total_2022 += 1\n",
    "\n",
    "print(f\"\\nResults on test set:  {correct_2022} correct out of {total_2022} total.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with 2022 data (ten classes)\n",
    "\n",
    "|          |   KNN   | Decision Tree | Random Forest| Neural Network |\n",
    "| -------- | ------- |  -----------  |  ----------- |  -----------   |\n",
    "| Training | 12.27 % |    21.22 %    |    16.45 %   |     19.38 %    |\n",
    "| Testing  | 12.43 % |    21.13 %    |    16.71 %   |     19.26 %    |\n",
    "|   2022   | 12.41 % |    23.35 %    |    16.34 %   |     17.95 %    |\n",
    "| 2022 (original) | 12.08 % |    10.78 %    |    14.26 %   |     16.75 %    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
