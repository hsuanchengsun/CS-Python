{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Welcome to ist341, week 3 !\n",
    "+ <b><tt>hw3pr0_ist341.ipynb</tt></b> is this week's reading-and-response\n",
    "+ Building algorithms is the central challenge of CS.\n",
    "+ This week's reading highlights some of the worries that can arise when those algorithms, in turn, seek to reflect human judgments, e.g., via machine learning from societal feedback, such as Google's auto-complete, or make judgments about people, e.g., to support doctors, employers, etc. \n",
    "+ This is happening in more and more contexts...\n",
    "\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Reading for hw3pr0_ist341... \n",
    "\n",
    "This week's article is about the unfairness/fairness of using algorithms when making decisions or judgments about people:\n",
    "\n",
    "+ [Here is the NYTimes article (from 2015)](https://www.nytimes.com/2015/07/10/upshot/when-algorithms-discriminate.html?_r=0)\n",
    "+ [Here is a local pdf, in case you're not able to access that article](https://www.cs.hmc.edu/twiki/pub/CS5Fall2020/Reading8/whenAlgorithmsDiscriminate.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "After reading the above article, respond to at least one of the following prompts (your choice):\n",
    "+ This article distinguishes between algorithms and authors, e.g., often, algorithms and online results simply reflect people's attitudes and behavior. <br> To what extent do you agree that algorithms are (or aren't) subjective as a judge of human beings?\n",
    "+ In another NYT article one individual suggests that, <i>\"We're always judging people in all sorts of ways, but without data we do it with a selection bias.\"</i> Do you feel algorithms have potential to make human interactions fairer? Or are they more likely to lead to less fairness or less attention to fairness? Your own thoughts, as always, can take a middle pathâ€”or a different path altogether.\n",
    "\n",
    "<br>\n",
    "\n",
    "There are many other articles and groups exploring this topic:\n",
    "+ There is an annual conference: http://www.fatml.org/\n",
    "+ An early paper addressing legal issues: https://arxiv.org/abs/1412.3756\n",
    "+ An accessible and illuminating [explanatory blog post](https://medium.com/@geomblog/when-an-algorithm-isn-t-2b9fe01b9bb5#.sjendul5h) by a researcher in this area, Suresh Venkatasubramanian.\n",
    "\n",
    "<br>\n",
    "\n",
    "As ever, don't feel obligated to go beyond a few sentences in total. An ideal response would show that you'd thought critically about the article's ideas -- and that you've brought your own ideas, background, and experience into your response.\n",
    "\n",
    "<hr> \n",
    "\n",
    "Submit your reflection here in this file (<b><tt>hw3pr0_ist341.ipynb</tt></b>)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading response\n",
    "\n",
    "(Feel free to use this cell for your response.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, I believe algorithms have biases and in recent algorithms, the problem become more serious than before. In the past, the algorithm are designed to help humans solve routine works or are built to run recursive experiments since the process is really long and humans can save lots of time by the algorithms. If there is bias in the result, that might be the bugs in the algorithms or the problems in the design of software and hardware. However, for the algorithm nowadays, we try to use them to learn and know the behavior of a human in order to create more profit and benefits from us. In this manner, algorithms are taught by us. They will learn what humans think and observe our behavior and take action based on that. Therefore, other than bugs in the algorithms, our bias would be recorded in the algorithms and their result would be based on the bias. In other words, algorithms are not able to help us avoid bias and judge fairly. Even worse, the algorithm may further make the bias and discrimination in society worse. If people do not realize there is bias in the algorithm, they would just follow the results with bias. Fortunately, we have realized the problem, so we still have time to solve them. One of my thought is that maybe we can discover the discrimination or bias from the result of algorithms. Then we can do more research on that to discover the bias and discrimination in society. As a result, we would be able to ease and eliminate them and make our world more harmonious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb4bb6bd67730c9185e6c24c983362cd7b4575b595bfae100d8d91e48f4f1e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
